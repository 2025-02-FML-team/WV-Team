{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2025-02-FML-team/WV-Team/blob/data_augment/03_model_data_agument2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hbeommd3-CQZ"
      },
      "source": [
        "# Model Training\n",
        "\n",
        "ì¼ë‹¨ í”¼ë“œë°± ëŒ€ë¡œ ì‹±ê¸€ëª°íŠ¸ ì¹´í…Œê³ ë¦¬ë§Œ ì¶”ê°€ì ìœ¼ë¡œ ë” ë„ìˆ˜ì— ë”°ë¼ì„œ ì¹´í…Œê³ ë¦¬ë¥¼ ë‚˜ëˆ„ì—ˆìœ¼ë©°, ê·¸ê²ƒì— ë”°ë¼ì„œ ì„±ëŠ¥ ì¸¡ì •ì„ í•  ê³„íšì…ë‹ˆë‹¤.\n",
        "Colabì„ ì´ìš© ì¤‘ì´ë¼ê³  í•˜ì‹œë©´ contentì•ˆì— ë¯¸ë¦¬ ë¹Œë“œëœ íŒŒì¼ì„ ë„£ê±°ë‚˜, driveì— ì—°ê²°í• ë•Œ ê¹Œì§€ ê¸°ë‹¤ë¦¬ë©´ ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJYmOIWP_fmZ"
      },
      "source": [
        "### Method 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nnUjew7fFqs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DATA_DIR = Path('/content/unpacked/')\n",
        "    PACK_DIR = Path('/content/drive/My Drive/colab_drive/prepacked.zip')\n",
        "    shutil.copy(PACK_DIR, '/content/')\n",
        "    !unzip -o -q /content/prepacked.zip -d {DATA_DIR}\n",
        "else:\n",
        "    DATA_DIR= Path(os.path.join(os.getcwd(), \"../data/\")).resolve()\n",
        "DATA_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4EoEDbMfFqs"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# CSV ë¡œë“œ ë° ì •ë¦¬, ë³¸ì¸ ê²½ë¡œì— ë§ê²Œ ë³€í™˜\n",
        "CSV_PATH = DATA_DIR / 'whiskies_recategorized.csv'\n",
        "IMAGE_SIZE = (128, 128)\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë‘˜ì¤‘í•˜ë‚˜ë§Œ ì‹¤í–‰ ì•„ë˜ê±°ëŠ” Ryeì‚­ì œ sm40,43í†µí•©"
      ],
      "metadata": {
        "id": "Q9mPma5757O1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOgkj5FUCf0I"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(CSV_PATH, dtype={\"id\": str})\n",
        "df[\"id\"] = df[\"id\"].astype(str).str.strip().str.replace(r\"\\.0$\", \"\", regex=True)\n",
        "df[\"category\"] = df[\"category\"].astype(str).str.strip()\n",
        "paths = [DATA_DIR / p for p in df[\"local_full_path\"]]\n",
        "\n",
        "bar = tqdm(paths, desc=\"Processing Images\", unit=\"img\")\n",
        "\n",
        "# ì´ë¯¸ì§€ ë¡œë“œ\n",
        "X_list = []\n",
        "for p in bar:\n",
        "    with Image.open(p) as im:\n",
        "        im = im.convert(\"RGB\")\n",
        "        im = im.resize(IMAGE_SIZE)\n",
        "        arr = np.asarray(im, dtype=np.uint8)\n",
        "        X_list.append(arr)\n",
        "X = np.stack(X_list, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(CSV_PATH, dtype={\"id\": str})\n",
        "df[\"id\"] = df[\"id\"].astype(str).str.strip().str.replace(r\"\\.0$\", \"\", regex=True)\n",
        "df[\"category\"] = df[\"category\"].astype(str).str.strip()\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# ğŸ”¥ 1) Rye ì‚­ì œ\n",
        "df = df[df[\"category\"] != \"Rye\"]\n",
        "\n",
        "# ğŸ”¥ 2) SM_40_43 + SM_43_46 â†’ SM_40_46 ë³‘í•©\n",
        "df[\"category\"] = df[\"category\"].replace({\n",
        "    \"SM_40_43\": \"SM_40_46\",\n",
        "    \"SM_43_46\": \"SM_40_46\"\n",
        "})\n",
        "# ---------------------------------------------------\n",
        "\n",
        "# ì´ë¯¸ì§€ ê²½ë¡œ ì„¸íŒ…\n",
        "paths = [DATA_DIR / p for p in df[\"local_full_path\"]]\n",
        "\n",
        "bar = tqdm(paths, desc=\"Processing Images\", unit=\"img\")\n",
        "\n",
        "# ì´ë¯¸ì§€ ë¡œë“œ\n",
        "X_list = []\n",
        "for p in bar:\n",
        "    with Image.open(p) as im:\n",
        "        im = im.convert(\"RGB\")\n",
        "        im = im.resize(IMAGE_SIZE)\n",
        "        arr = np.asarray(im, dtype=np.uint8)\n",
        "        X_list.append(arr)\n",
        "X = np.stack(X_list, axis=0)"
      ],
      "metadata": {
        "id": "siy5Xixn52X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------"
      ],
      "metadata": {
        "id": "Hh1HJCiy545v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë‘˜ì¤‘í•˜ë‚˜ ì„ íƒ ì•„ë˜ê±°ëŠ” validatoinìœ¼ë¡œë„ ë‚˜ëˆ” 72:18:10"
      ],
      "metadata": {
        "id": "vbvFpyfD74k6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¼ë²¨ ì¸ì½”ë”©\n",
        "labels = df[\"category\"].values\n",
        "le = LabelEncoder()\n",
        "y_int = le.fit_transform(labels)\n",
        "\n",
        "# train/test ë¶„ë¦¬\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    X, y_int, test_size=0.2, random_state=RANDOM_STATE, stratify=y_int\n",
        ")\n",
        "\n",
        "print(\"train_images:\", train_images.shape)\n",
        "print(\"test_images:\", test_images.shape)\n",
        "print(\"train_labels ë¶„í¬:\", np.bincount(train_labels))\n",
        "print(\"test_labels ë¶„í¬:\", np.bincount(test_labels))\n",
        "print(\"class mapping:\", dict(zip(le.classes_, range(len(le.classes_)))))"
      ],
      "metadata": {
        "id": "6ZH4snomiOLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1) ì›ë˜ train/test ë¶„ë¦¬\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    X, y_int, test_size=0.1, random_state=RANDOM_STATE, stratify=y_int\n",
        ")\n",
        "\n",
        "# 2) train â†’ train/validation ì¬ë¶„ë¦¬ (trainì˜ 20%ë¥¼ valë¡œ)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels,\n",
        "    test_size=0.2,   # trainì˜ 20% = ì „ì²´ì˜ 16% ì •ë„ê°€ validationìœ¼ë¡œ ê°€ê²Œ ë¨\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=train_labels\n",
        ")\n",
        "\n",
        "print(\"train_images:\", train_images.shape)\n",
        "print(\"val_images:\", val_images.shape)\n",
        "print(\"test_images:\", test_images.shape)\n",
        "\n",
        "print(\"train_labels ë¶„í¬:\", np.bincount(train_labels))\n",
        "print(\"val_labels ë¶„í¬:\", np.bincount(val_labels))\n",
        "print(\"test_labels ë¶„í¬:\", np.bincount(test_labels))"
      ],
      "metadata": {
        "id": "2tdnZfQi72vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------"
      ],
      "metadata": {
        "id": "gUurP-H18AoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# í´ë˜ìŠ¤ë³„ ê°œìˆ˜ í™•ì¸\n",
        "counter = Counter(train_labels)\n",
        "print(\"Before augmentation:\", counter)\n",
        "\n",
        "# ì¦ê°•ìš© ë°ì´í„° ì œë„ˆë ˆì´í„° ì„¤ì •\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,       # 20ë„ê¹Œì§€ íšŒì „\n",
        "    horizontal_flip=True,    # ì¢Œìš° ë°˜ì „\n",
        "    width_shift_range=0.1,   # ì¢Œìš° ì´ë™\n",
        "    height_shift_range=0.1,  # ìƒí•˜ ì´ë™\n",
        "    zoom_range=0.1           # ì•½ê°„ì˜ í™•ëŒ€/ì¶•ì†Œ\n",
        ")\n",
        "\n",
        "target_count = max(counter.values())  # ê°€ì¥ ë§ì€ í´ë˜ìŠ¤ ìˆ˜\n",
        "\n",
        "aug_images = []\n",
        "aug_labels = []\n",
        "\n",
        "for cls, count in counter.items():\n",
        "    cls_indices = np.where(train_labels == cls)[0]\n",
        "    n_needed = target_count - count\n",
        "\n",
        "    if n_needed > 0:\n",
        "        for i in range(n_needed):\n",
        "            idx = np.random.choice(cls_indices)\n",
        "            img = train_images[idx]\n",
        "            img = np.expand_dims(img, 0)  # ImageDataGeneratorëŠ” 4D ì…ë ¥ í•„ìš”\n",
        "\n",
        "            # ì¦ê°• ì´ë¯¸ì§€ í•œ ì¥ ìƒì„±\n",
        "            for batch in datagen.flow(img, batch_size=1):\n",
        "                aug_img = batch[0].astype(np.uint8)\n",
        "                aug_images.append(aug_img)\n",
        "                aug_labels.append(cls)\n",
        "                break  # 1ì¥ë§Œ ìƒì„±\n",
        "\n",
        "# ê¸°ì¡´ ë°ì´í„°ì™€ í•©ì¹˜ê¸°\n",
        "if aug_images:\n",
        "    train_images = np.concatenate([train_images, np.array(aug_images)], axis=0)\n",
        "    train_labels = np.concatenate([train_labels, np.array(aug_labels)], axis=0)\n",
        "\n",
        "# í™•ì¸\n",
        "counter_after = Counter(train_labels)\n",
        "print(\"After augmentation:\", counter_after)"
      ],
      "metadata": {
        "id": "Tle7gctW0-ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F618rP6t_0W1"
      },
      "source": [
        "ì—¬ê¸°ì„œë¶€í„°ëŠ” ëª¨ë¸ ì‹¤í–‰ ì½”ë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeyF9hXMbxT2"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.Input(shape=(128, 128, 3)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(8, activation='softmax'),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ4l__Doccbi"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer= \"rmsprop\",\n",
        "              loss = \"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4sn5wVRACcO"
      },
      "source": [
        "ë°©ë²•2ë¥¼ ê³¨ëì„ ê²½ìš° 128 * 128 * 3ì„ 128 * 256 * 3ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7rSj-Y_ctRf"
      },
      "outputs": [],
      "source": [
        "# train_images = train_images.reshape((train_images.shape[0], 256*256*3))\n",
        "# test_images  = test_images.reshape((test_images.shape[0], 256*256*3))\n",
        "# RAM ë³´ì¡´ì„ ìœ„í•´ì„œ ì´ë ‡ê²Œ copyí•˜ì§€ ì•Šê³  normalizeí•©ë‹ˆë‹¤.\n",
        "train_images = train_images.astype(\"float32\", copy=False)\n",
        "test_images = test_images.astype(\"float32\", copy=False)\n",
        "train_images /= 255.0\n",
        "test_images /= 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI45JJdOrizV"
      },
      "outputs": [],
      "source": [
        "print(train_images.shape, train_images.dtype)\n",
        "print(train_labels.shape, train_labels[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dIRs_lqdG8w"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_images, train_labels, epochs=30, batch_size=64)\n",
        "#history = model.fit(train_images, train_labels, validation_data=(val_images, val_labels), epochs=30, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(acc)\n",
        "plt.plot(val_acc)\n",
        "plt.legend(['train','val'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Du8JjOCt8Zmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfhDOr_lhiib"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# ì˜ˆì¸¡\n",
        "y_pred = np.argmax(model.predict(test_images), axis=1)\n",
        "\n",
        "# í´ë˜ìŠ¤ë³„ ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, F1 ì ìˆ˜ ì¶œë ¥\n",
        "report = classification_report(\n",
        "    test_labels,\n",
        "    y_pred,\n",
        "    target_names=le.classes_,\n",
        "    digits=3\n",
        ")\n",
        "print(report)\n",
        "\n",
        "# (ì„ íƒ) í˜¼ë™ í–‰ë ¬ ì‹œê°í™”\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(test_labels, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=le.classes_,\n",
        "            yticklabels=le.classes_)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix by Category\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pqBy6-NdQ6mB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}