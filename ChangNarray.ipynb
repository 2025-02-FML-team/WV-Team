{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPob9WcYJ5NkBHStZDh89Uy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2025-02-FML-team/WV-Team/blob/change_numpyarray/ChangNarray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PATH와 DIR은 여러분이 가진 폴더와 파일 경로에 맞게 바꾸시길 바랍니다.\n",
        "\n",
        "싱글몰트가 너무 많아서 개수를 줄였고, 라이와 브랜디가 너무 적어서 라이와 브랜디는 완전히 삭제 했습니다. 즉 category는 4개입니다.\n",
        "\n",
        "train_image, train_label, test_image, test_label을 나누는 방법을 세가지로 바꿨습니다. 세가지로 바꾼이유는 셋다 accuracy가 안나온다는 것을 보여주기 위함입니다."
      ],
      "metadata": {
        "id": "Hbeommd3-CQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "image, label, train, test set 나누기 방법 1"
      ],
      "metadata": {
        "id": "kJYmOIWP_fmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# CSV 로드 및 정리, 본인 경로에 맞게 변환\n",
        "CSV_PATH = \"/content/whiskies_filtered.csv\"\n",
        "IMAGE_DIR = \"/content/crops/crops\"\n",
        "IMAGE_SIZE = (128, 128)\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "df = pd.read_csv(CSV_PATH, dtype={\"id\": str})\n",
        "df[\"id\"] = df[\"id\"].astype(str).str.strip().str.replace(r\"\\.0$\", \"\", regex=True)\n",
        "df[\"category\"] = df[\"category\"].astype(str).str.strip()\n",
        "\n",
        "# 라이, 브랜디 완전 삭제\n",
        "df = df[~df[\"category\"].isin([\"라이\", \"브랜디\"])].copy()\n",
        "\n",
        "# 싱글몰트는 CSV 행(=id 기준)에서 600개 삭제\n",
        "singlemalt_df = df[df[\"category\"] == \"싱글몰트\"]\n",
        "if singlemalt_df.shape[0] > 600:\n",
        "    # 싱글몰트 중 600개를 랜덤하게 제거\n",
        "    drop_idx = singlemalt_df.sample(600, random_state=RANDOM_STATE).index\n",
        "    df = df.drop(index=drop_idx).reset_index(drop=True)\n",
        "\n",
        "print(\"최종 category 분포:\\n\", df[\"category\"].value_counts())\n",
        "\n",
        "# id → category 매핑\n",
        "id2cat = dict(zip(df[\"id\"], df[\"category\"]))\n",
        "\n",
        "\n",
        "# 이미지 매칭 (jpg만 사용)\n",
        "image_files = glob.glob(os.path.join(IMAGE_DIR, \"**\", \"*.jpg\"), recursive=True)\n",
        "\n",
        "paths, labels, unmatched = [], [], []\n",
        "for f in image_files:\n",
        "    fname = os.path.basename(f)\n",
        "    base = os.path.splitext(fname)[0]\n",
        "    m = re.search(r\"\\d{6,}\", base)  # 파일명에서 숫자(id) 추출\n",
        "    if not m:\n",
        "        unmatched.append(fname)\n",
        "        continue\n",
        "    id_part = m.group(0)\n",
        "    if id_part in id2cat:\n",
        "        paths.append(f)\n",
        "        labels.append(id2cat[id_part])\n",
        "    else:\n",
        "        unmatched.append(fname)\n",
        "\n",
        "print(f\"매칭된 이미지 수: {len(paths)}\")\n",
        "print(f\"매칭되지 않은 이미지 수: {len(unmatched)}\")\n",
        "\n",
        "if len(paths) == 0:\n",
        "    raise RuntimeError(\"일치하는 이미지가 없습니다. CSV의 id 형식 또는 파일명 규칙을 확인하세요.\")\n",
        "\n",
        "\n",
        "# 이미지 로드\n",
        "X_list = []\n",
        "for p in paths:\n",
        "    with Image.open(p) as im:\n",
        "        im = im.convert(\"RGB\")\n",
        "        im = im.resize(IMAGE_SIZE)\n",
        "        arr = np.asarray(im, dtype=np.uint8)\n",
        "        X_list.append(arr)\n",
        "X = np.stack(X_list, axis=0)\n",
        "\n",
        "\n",
        "# 라벨 인코딩\n",
        "le = LabelEncoder()\n",
        "y_int = le.fit_transform(labels)\n",
        "\n",
        "\n",
        "# train/test 분리\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    X, y_int, test_size=0.2, random_state=RANDOM_STATE, stratify=y_int\n",
        ")\n",
        "\n",
        "print(\"train_images:\", train_images.shape)\n",
        "print(\"test_images:\", test_images.shape)\n",
        "print(\"train_labels 분포:\", np.bincount(train_labels))\n",
        "print(\"class mapping:\", dict(zip(le.classes_, range(len(le.classes_)))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOgkj5FUCf0I",
        "outputId": "caaa10e6-d9db-4287-9b0b-2bab67ef27d4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 category 분포:\n",
            " category\n",
            "싱글몰트    543\n",
            "블렌디드    376\n",
            "기타      286\n",
            "버번      186\n",
            "Name: count, dtype: int64\n",
            "매칭된 이미지 수: 2726\n",
            "매칭되지 않은 이미지 수: 1490\n",
            "train_images: (2180, 128, 128, 3)\n",
            "test_images: (546, 128, 128, 3)\n",
            "train_labels 분포: [442 288 591 859]\n",
            "class mapping: {np.str_('기타'): 0, np.str_('버번'): 1, np.str_('블렌디드'): 2, np.str_('싱글몰트'): 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "image, label, train, test set 나누기 방법 2"
      ],
      "metadata": {
        "id": "w3UfBj45_piG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# CSV 로드 및 정리\n",
        "CSV_PATH = \"/content/whiskies_filtered.csv\"\n",
        "IMAGE_DIR = \"/content/crops/crops\"\n",
        "IMAGE_SIZE = (128, 128)\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "df = pd.read_csv(CSV_PATH, dtype={\"id\": str})\n",
        "df[\"id\"] = df[\"id\"].astype(str).str.strip().str.replace(r\"\\.0$\", \"\", regex=True)\n",
        "df[\"category\"] = df[\"category\"].astype(str).str.strip()\n",
        "\n",
        "#라이, 브랜디 완전 삭제\n",
        "df = df[~df[\"category\"].isin([\"라이\", \"브랜디\"])].copy()\n",
        "\n",
        "#싱글몰트는 CSV 행(=id 기준)에서 600개 삭제\n",
        "singlemalt_df = df[df[\"category\"] == \"싱글몰트\"]\n",
        "other_df = df[df[\"category\"] != \"싱글몰트\"]\n",
        "\n",
        "if singlemalt_df.shape[0] > 600:\n",
        "    drop_idx = singlemalt_df.sample(600, random_state=RANDOM_STATE).index\n",
        "    df = df.drop(index=drop_idx).reset_index(drop=True)\n",
        "\n",
        "print(\"최종 category 분포:\\n\", df[\"category\"].value_counts())\n",
        "\n",
        "id2cat = dict(zip(df[\"id\"], df[\"category\"]))\n",
        "\n",
        "\n",
        "#이미지 매칭 (jpg만 사용)\n",
        "image_files = glob.glob(os.path.join(IMAGE_DIR, \"**\", \"*.jpg\"), recursive=True)\n",
        "\n",
        "# id별 이미지 경로 모으기\n",
        "id_to_files = {}\n",
        "for f in image_files:\n",
        "    fname = os.path.basename(f)\n",
        "    m = re.search(r\"(\\d+)_\\d+\", fname)\n",
        "    if not m:\n",
        "        continue\n",
        "    id_part = m.group(1)\n",
        "    if id_part not in id_to_files:\n",
        "        id_to_files[id_part] = []\n",
        "    id_to_files[id_part].append(f)\n",
        "\n",
        "# 이미지 로드 및 병합 (128x256)\n",
        "X_list, y_list = [], []\n",
        "for id_part, files in id_to_files.items():\n",
        "    if id_part not in id2cat:\n",
        "        continue  # CSV에 없는 id는 제외\n",
        "\n",
        "    # 파일 2개만 사용 (1_label, 2_label)\n",
        "    files = sorted(files)[:2]\n",
        "    if len(files) < 2:\n",
        "        continue  # 짝이 안 맞으면 skip\n",
        "\n",
        "    imgs = []\n",
        "    for p in files:\n",
        "        with Image.open(p) as im:\n",
        "            im = im.convert(\"RGB\")\n",
        "            im = im.resize(IMAGE_SIZE)\n",
        "            imgs.append(np.asarray(im, dtype=np.uint8))\n",
        "\n",
        "    # 두 이미지를 좌우로 붙이기 (128, 128, 3) + (128, 128, 3) → (128, 256, 3)\n",
        "    merged = np.concatenate(imgs, axis=1)\n",
        "    X_list.append(merged)\n",
        "    y_list.append(id2cat[id_part])\n",
        "\n",
        "X = np.stack(X_list, axis=0)\n",
        "labels = np.array(y_list)\n",
        "\n",
        "print(f\"최종 병합된 이미지 수: {len(X_list)}\")\n",
        "print(f\"이미지 shape 예시: {X.shape}\")\n",
        "\n",
        "# 라벨 인코딩\n",
        "le = LabelEncoder()\n",
        "y_int = le.fit_transform(labels)\n",
        "\n",
        "# train/test 분리\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    X, y_int, test_size=0.2, random_state=RANDOM_STATE, stratify=y_int\n",
        ")\n",
        "\n",
        "print(\"train_images:\", train_images.shape)\n",
        "print(\"test_images:\", test_images.shape)\n",
        "print(\"train_labels 분포:\", np.bincount(train_labels))\n",
        "print(\"class mapping:\", dict(zip(le.classes_, range(len(le.classes_)))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqVxWPFYB7Ih",
        "outputId": "aa2efcaf-7ebd-40aa-e65e-c0d10204c8e3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 category 분포:\n",
            " category\n",
            "싱글몰트    543\n",
            "블렌디드    376\n",
            "기타      286\n",
            "버번      186\n",
            "Name: count, dtype: int64\n",
            "최종 병합된 이미지 수: 1335\n",
            "이미지 shape 예시: (1335, 128, 256, 3)\n",
            "train_images: (1068, 128, 256, 3)\n",
            "test_images: (267, 128, 256, 3)\n",
            "train_labels 분포: [214 139 290 425]\n",
            "class mapping: {np.str_('기타'): 0, np.str_('버번'): 1, np.str_('블렌디드'): 2, np.str_('싱글몰트'): 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "image, label, train, test set 나누기 방법 3"
      ],
      "metadata": {
        "id": "OP_0wTNg_rMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# CSV 로드 및 정리, 본인 경로에 맞게 변환\n",
        "CSV_PATH = \"/content/whiskies_filtered.csv\"\n",
        "IMAGE_DIR = \"/content/crops/crops\"\n",
        "IMAGE_SIZE = (128, 128)\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "df = pd.read_csv(CSV_PATH, dtype={\"id\": str})\n",
        "df[\"id\"] = df[\"id\"].astype(str).str.strip().str.replace(r\"\\.0$\", \"\", regex=True)\n",
        "df[\"category\"] = df[\"category\"].astype(str).str.strip()\n",
        "\n",
        "#라이, 브랜디 완전 삭제\n",
        "df = df[~df[\"category\"].isin([\"라이\", \"브랜디\"])].copy()\n",
        "\n",
        "#싱글몰트는 CSV 행(=id 기준)에서 600개 삭제\n",
        "singlemalt_df = df[df[\"category\"] == \"싱글몰트\"]\n",
        "other_df = df[df[\"category\"] != \"싱글몰트\"]\n",
        "\n",
        "if singlemalt_df.shape[0] > 600:\n",
        "    drop_idx = singlemalt_df.sample(600, random_state=RANDOM_STATE).index\n",
        "    df = df.drop(index=drop_idx).reset_index(drop=True)\n",
        "\n",
        "print(\"최종 category 분포:\\n\", df[\"category\"].value_counts())\n",
        "\n",
        "# id → category 매핑\n",
        "id2cat = dict(zip(df[\"id\"], df[\"category\"]))\n",
        "\n",
        "\n",
        "image_files = glob.glob(os.path.join(IMAGE_DIR, \"**\", \"*.jpg\"), recursive=True)\n",
        "\n",
        "paths, labels, unmatched = [], [], []\n",
        "\n",
        "for f in image_files:\n",
        "    fname = os.path.basename(f)\n",
        "\n",
        "    # _1_ 이 포함된 파일은 건너뜀\n",
        "    if \"_1_\" in fname:\n",
        "        continue\n",
        "\n",
        "    base = os.path.splitext(fname)[0]\n",
        "    m = re.search(r\"\\d{6,}\", base)\n",
        "    if not m:\n",
        "        unmatched.append(fname)\n",
        "        continue\n",
        "\n",
        "    id_part = m.group(0)\n",
        "    if id_part in id2cat:\n",
        "        paths.append(f)\n",
        "        labels.append(id2cat[id_part])\n",
        "    else:\n",
        "        unmatched.append(fname)\n",
        "\n",
        "print(f\"매칭된 이미지 수: {len(paths)}\")\n",
        "print(f\"매칭되지 않은 이미지 수: {len(unmatched)}\")\n",
        "\n",
        "if len(paths) == 0:\n",
        "    raise RuntimeError(\"일치하는 이미지가 없슴. CSV의 id 형식 또는 파일명 규칙 확인\")\n",
        "\n",
        "\n",
        "# 이미지 로드 (_2_ 이미지만 사용)\n",
        "X_list = []\n",
        "for p in paths:\n",
        "    with Image.open(p) as im:\n",
        "        im = im.convert(\"RGB\")\n",
        "        im = im.resize(IMAGE_SIZE)\n",
        "        arr = np.asarray(im, dtype=np.uint8)\n",
        "        X_list.append(arr)\n",
        "X = np.stack(X_list, axis=0)\n",
        "\n",
        "\n",
        "# 라벨 인코딩\n",
        "le = LabelEncoder()\n",
        "y_int = le.fit_transform(labels)\n",
        "\n",
        "\n",
        "# train/test 분리\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    X, y_int, test_size=0.2, random_state=RANDOM_STATE, stratify=y_int\n",
        ")\n",
        "\n",
        "print(\"train_images:\", train_images.shape)\n",
        "print(\"test_images:\", test_images.shape)\n",
        "print(\"train_labels 분포:\", np.bincount(train_labels))\n",
        "print(\"class mapping:\", dict(zip(le.classes_, range(len(le.classes_)))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJcpxuxMA641",
        "outputId": "cabfbfc6-4a01-402b-9fce-a83f49ae0a9a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 category 분포:\n",
            " category\n",
            "싱글몰트    543\n",
            "블렌디드    376\n",
            "기타      286\n",
            "버번      186\n",
            "Name: count, dtype: int64\n",
            "매칭된 이미지 수: 1391\n",
            "매칭되지 않은 이미지 수: 754\n",
            "train_images: (1112, 128, 128, 3)\n",
            "test_images: (279, 128, 128, 3)\n",
            "train_labels 분포: [229 149 300 434]\n",
            "class mapping: {np.str_('기타'): 0, np.str_('버번'): 1, np.str_('블렌디드'): 2, np.str_('싱글몰트'): 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# train 데이터 분포 확인\n",
        "train_label_names = le.inverse_transform(train_labels)\n",
        "test_label_names = le.inverse_transform(test_labels)\n",
        "\n",
        "print(\" Train 라벨\")\n",
        "print(pd.Series(train_label_names).value_counts())\n",
        "\n",
        "print(\"\\nTest 라벨\")\n",
        "print(pd.Series(test_label_names).value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdO9V6Hf6B0C",
        "outputId": "e522a001-a920-434a-fee4-dc4a770d55a7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Train 라벨\n",
            "싱글몰트    425\n",
            "블렌디드    290\n",
            "기타      214\n",
            "버번      139\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Test 라벨\n",
            "싱글몰트    106\n",
            "블렌디드     73\n",
            "기타       53\n",
            "버번       35\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서부터는 강의록2에 있는 코드입니다.\n",
        "\n",
        "위에 있는 3가지 방법중에 하나를 고르고 아래 코드를 실행시키면 됩니다."
      ],
      "metadata": {
        "id": "F618rP6t_0W1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(4, activation=\"softmax\"),\n",
        "])"
      ],
      "metadata": {
        "id": "VeyF9hXMbxT2"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer= \"rmsprop\",\n",
        "              loss = \"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "tZ4l__Doccbi"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "방법2를 골랐을 경우 128 * 128 * 3을 128 * 256 * 3으로 바꿔주세요"
      ],
      "metadata": {
        "id": "i4sn5wVRACcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((train_images.shape[0], 128*128*3))\n",
        "test_images  = test_images.reshape((test_images.shape[0], 128*128*3))\n",
        "train_images = train_images.astype(\"float32\")/255\n",
        "test_images = test_images.astype(\"float32\")/255"
      ],
      "metadata": {
        "id": "l7rSj-Y_ctRf"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_images.shape, train_images.dtype)\n",
        "print(train_labels.shape, train_labels[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI45JJdOrizV",
        "outputId": "d6b14108-2e10-4810-cc1e-6b2a14949314"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2180, 49152) float32\n",
            "(2180,) [3 2 2 2 0 3 3 0 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=50, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "-dIRs_lqdG8w",
        "outputId": "a3087cd6-4d22-4def-e7c6-fc56a1460229"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 561ms/step - accuracy: 0.2839 - loss: 166.0871\n",
            "Epoch 2/50\n",
            "\u001b[1m14/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 581ms/step - accuracy: 0.3005 - loss: 20.7519"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1583226178.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfhDOr_lhiib",
        "outputId": "cbebc061-33ce-48e2-c7b7-60b410c17e56"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.2732 - loss: 7.6455\n",
            "0.301075279712677\n"
          ]
        }
      ]
    }
  ]
}