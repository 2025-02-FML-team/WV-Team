{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bba8009",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/2025-02-FML-team/WV-Team/blob/main/notebooks/05_class_balance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0f7cf03-adc0-4f43-af1e-cd17922b27be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0f7cf03-adc0-4f43-af1e-cd17922b27be",
    "outputId": "f40eaa54-2436-49fe-eb5a-8d115a146fb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/workspace/WV-Team/data')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_DIR = Path('/content/unpacked/')\n",
    "    PACK_DIR = Path('/content/drive/My Drive/colab_drive/prepacked.zip')\n",
    "    shutil.copy(PACK_DIR, '/content/')\n",
    "    !unzip -o -q /content/prepacked.zip -d {DATA_DIR}\n",
    "else:\n",
    "    DATA_DIR= Path(os.path.join(os.getcwd(), \"../data/\")).resolve()\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4558ab8-9cbb-400a-85c4-a313f8f4bd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 17:39:51.342090: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "configs = [\n",
    "    {\"name\": \"id384x256\", \"input_dim\": (384, 256)},\n",
    "    {\"name\": \"id336x224\", \"input_dim\": (336, 224)},\n",
    "    {\"name\": \"id256x384\", \"input_dim\": (256, 384)},\n",
    "    {\"name\": \"id224x336\", \"input_dim\": (224, 336)},\n",
    "]\n",
    "\n",
    "cv_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7puDIfStRQGs",
   "metadata": {
    "id": "7puDIfStRQGs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# CSV 로드 및 정리, 본인 경로에 맞게 변환\n",
    "CSV_PATH = DATA_DIR / 'whiskies_relabel.csv'\n",
    "#IMAGE_SIZE = (256, 256)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "tf.random.set_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9zlQt6BNRWMF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "153e3daeac704ae8bd3a845e761f5c69",
      "02ebafc09f1a4e7ba20e2a1cf9fccfe9",
      "5087e63df54a4a7aa2c8fdbee60dda43",
      "9b6363585a834d68b424bd09693be95e",
      "5a37bae3144f4a5ebc361db1d02ecc15",
      "81589a93cdd848358ce75973668acdbc",
      "837cd80e9aec4987a0bfe36254a53c4c",
      "2c08b7b452be4dff98eb95d8a2aaeb91",
      "cbcf43f91a824e80aa0745e3cc57e6b3",
      "0bf88e29d24f4c1c8da7ca5f681233dc",
      "93a9cd26f71f4ff8ac955fcfc8208bef"
     ]
    },
    "id": "9zlQt6BNRWMF",
    "outputId": "5b0b58d4-38bb-475b-c9d5-05ed6e88ce97"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be732b1770a1402fbf915f2e148e9711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Images:   0%|          | 0/3042 [00:00<?, ?img/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH, dtype={\"id\": str})\n",
    "df[\"id\"] = df[\"id\"].astype(str).str.strip().str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "df[\"category\"] = df[\"category\"].astype(str).str.strip()\n",
    "paths = [DATA_DIR / p for p in df[\"local_full_path\"]]\n",
    "\n",
    "bar = tqdm(paths, desc=\"Processing Images\", unit=\"img\")\n",
    "\n",
    "# 이미지 로드\n",
    "X_list = []\n",
    "for p in bar:\n",
    "    with Image.open(p) as im:\n",
    "        im = im.convert(\"RGB\")\n",
    "        #im = im.resize(IMAGE_SIZE) #retain the original size\n",
    "        arr = np.asarray(im, dtype=np.uint8)\n",
    "        X_list.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f24ed66e-bc6d-4f6b-a8f8-6c9c9028f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_batch(images, size):\n",
    "    out = []\n",
    "    for img in images:\n",
    "        im = Image.fromarray(img)\n",
    "        im = im.resize((size[1], size[0], ))\n",
    "        out.append(np.asarray(im, dtype=np.uint8))\n",
    "    return np.stack(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c08e4a07-aea8-46e8-8528-27604b64876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_batches = []\n",
    "\n",
    "for cfg in configs:\n",
    "    X_adjusted = resize_batch(X_list, cfg[\"input_dim\"])\n",
    "    config_batches.append(X_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "LZsc1nB0RYSi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZsc1nB0RYSi",
    "outputId": "93df3f32-6828-48ef-95d1-75aa7a36bfd1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# 라벨 인코딩\n",
    "labels = df[\"category\"].values\n",
    "le = LabelEncoder()\n",
    "y_int = le.fit_transform(labels)\n",
    "CLASS_NUM = len(le.classes_)\n",
    "datas = []\n",
    "\n",
    "for index in range(len(configs)):\n",
    "    name = configs[index][\"name\"]\n",
    "    X_adjusted = config_batches[index]\n",
    "    # test 분리\n",
    "    X_rest, X_test, y_rest, y_test = train_test_split(\n",
    "        X_adjusted, y_int,\n",
    "        test_size=0.2,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y_int\n",
    "    )\n",
    "\n",
    "    data = { \"X_rest\": X_rest, \"X_test\": X_test, \"y_rest\": y_rest, \"y_test\": y_test }\n",
    "    datas.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0t6FOrHAVq0u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0t6FOrHAVq0u",
    "outputId": "d7385606-d271-45d1-a6e7-d2bfd88c9784"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#굳이 이렇게 할 필요는 1도 없지만 지금 도저히 더 좋은 코드를 짤 수 있는 상황이 아님\n",
    "def get_class_weight(y_train):\n",
    "    class_weights_array = compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=np.array(range(CLASS_NUM)),\n",
    "        y=y_train,\n",
    "    )\n",
    "    \n",
    "    class_weight_dict = {}\n",
    "    \n",
    "    i = 0;\n",
    "    for weight in class_weights_array:\n",
    "        class_weight_dict[i] = weight\n",
    "        i += 1\n",
    "\n",
    "    return class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a-SqhAtxR-X7",
   "metadata": {
    "id": "a-SqhAtxR-X7"
   },
   "outputs": [],
   "source": [
    "#03 노트북 코드++\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class ControllerCallback(Callback):\n",
    "    def __init__(self, X_val, y_val, start_from_epoch=12, patient=3, tqdm=None):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.f1_scores = [] #this is for cumilating f1 per epoch\n",
    "        self.start_from_epoch = start_from_epoch\n",
    "        self.patient = patient\n",
    "        self.out = 0\n",
    "        self.best_f1 = -1\n",
    "        self.epochs = 0\n",
    "        self.tqdm = tqdm\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epochs += 1\n",
    "        y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        if self.y_val.ndim == 2:\n",
    "            y_true = np.argmax(self.y_val, axis=1)\n",
    "        else:\n",
    "            y_true = self.y_val\n",
    "\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        self.f1_scores.append(f1)\n",
    "        logs['val_macro_f1'] = f1\n",
    "\n",
    "        if f1 > self.best_f1:\n",
    "            self.best_f1 = f1\n",
    "\n",
    "        if 1 < epoch and epoch > self.start_from_epoch and f1 < self.f1_scores[-2]:\n",
    "            if not tqdm:\n",
    "                print(f\"\\nNon Improvement detected at EP : {epoch}, f1 : {f1}\")\n",
    "            self.out += 1\n",
    "\n",
    "        if self.tqdm:\n",
    "            self.tqdm.set_postfix(epochs=self.epochs, curr_f1=f1, best_f1=self.best_f1, strikes=self.out)\n",
    "\n",
    "        if self.out >= self.patient:\n",
    "            if not tqdm:\n",
    "                print(f\"\\nStopping at EP : {epoch}, f1 : {f1}\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tfkknavsSKBM",
   "metadata": {
    "id": "tfkknavsSKBM"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.activations import gelu\n",
    "\n",
    "#the name keyword is just there to use kwargs, it's not actually used.\n",
    "def build_model(\n",
    "    hidden=[200, 200],\n",
    "    conv=[16, 32, 48],\n",
    "    conv_double=True,\n",
    "    input_dim=(256, 256),\n",
    "    name=\"\"\n",
    "):\n",
    "    inputs = keras.Input(shape=(input_dim[0], input_dim[1], 3))\n",
    "\n",
    "    x = inputs\n",
    "    for cl in conv:\n",
    "        x = layers.Conv2D(cl, (3,3), activation='relu', padding='same')(x)\n",
    "        if conv_double:\n",
    "            x = layers.Conv2D(cl, (3,3), activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    for hl in hidden:\n",
    "        x = layers.Dense(hl)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('gelu')(x)\n",
    "\n",
    "    outputs = layers.Dense(CLASS_NUM, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9185094-a841-401d-a446-e8a6ac9f0eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "uEESi5nKWhxG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uEESi5nKWhxG",
    "outputId": "217f2c50-8718-443b-d35f-5b9619fe9c0e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ea46db89ac49d0bc8a1d28e2549dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model Configurations:   0%|          | 0/3 [00:00<?, ?config/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b68bbfe871648bd97701aea790893f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "st K-fold:   0%|          | 0/5 [00:00<?, ?fold/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 18:02:25.456394: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-11-23 18:02:25.663682: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1511', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-11-23 18:02:26.068056: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1513', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2025-11-23 18:02:33.864830: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1511', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-11-23 18:06:45.781841: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1511', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [CV Summary] id336x224: f1_macro=0.4922 ± 0.0125, last_f1_macro=0.4256 ± 0.1286, acc=0.4612 ± 0.1208, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e6c1724c4947a89fb4465452a2e1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "st K-fold:   0%|          | 0/5 [00:00<?, ?fold/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 18:09:12.086129: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-11-23 18:09:12.632289: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1513', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2025-11-23 18:09:22.183042: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_654', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-11-23 18:14:05.982315: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_654', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [CV Summary] id256x384: f1_macro=0.4926 ± 0.0249, last_f1_macro=0.4849 ± 0.0243, acc=0.5154 ± 0.0211, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73687a3edbc04af18af79efd82dc0114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "st K-fold:   0%|          | 0/5 [00:00<?, ?fold/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 18:16:39.954146: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-11-23 18:16:40.486731: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1513', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [CV Summary] id224x336: f1_macro=0.5153 ± 0.0166, last_f1_macro=0.5033 ± 0.0123, acc=0.5302 ± 0.0153, \n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "\n",
    "# ----- 설정 값들 -----\n",
    "N_SPLITS   = 5      # k-fold 개수\n",
    "EPOCHS     = 50     # 최대 epoch\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=N_SPLITS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "#버그로 끊겨서 이렇게 하였을 뿐, 나중에 다시 돌려놔야함 TODO\n",
    "bar_cfg = tqdm(configs[1:], desc=\"Model Configurations\", unit=\"config\")\n",
    "data_index = 1\n",
    "\n",
    "for cfg in bar_cfg:\n",
    "    name = cfg[\"name\"]\n",
    "    bar_cfg.set_postfix(name=name)\n",
    "\n",
    "    fold_accuracies = []\n",
    "    fold_precisions = []\n",
    "    fold_f1s        = []\n",
    "    fold_last_f1s   = []\n",
    "\n",
    "    # k-fold 루프\n",
    "    bar_fold = tqdm(enumerate(skf.split(X_rest, y_rest), start=1), desc=\"st K-fold\", unit=\"fold\", total=N_SPLITS)\n",
    "    for fold_idx, (train_idx, val_idx) in bar_fold:\n",
    "        bar_fold.desc = f'st K-fold, fold:{fold_idx}'\n",
    "\n",
    "        X_tr, X_val = datas[data_index][\"X_rest\"][train_idx], datas[data_index][\"X_rest\"][val_idx]\n",
    "        y_tr, y_val = datas[data_index][\"y_rest\"][train_idx], datas[data_index][\"y_rest\"][val_idx]\n",
    "        class_weight = get_class_weight(y_tr)\n",
    "\n",
    "        # 모델 생성(컴파일도 여기서 진행!)\n",
    "        model = build_model(**cfg)\n",
    "        #model.summary() #debug\n",
    "\n",
    "        # f1 + early stopping + progress\n",
    "        controller = ControllerCallback(\n",
    "            X_val, y_val,\n",
    "            start_from_epoch=15,\n",
    "            patient=5,\n",
    "            tqdm=bar_fold\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            X_tr, y_tr,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks=[controller],\n",
    "            class_weight=class_weight, #이렇게 하면 class weight를 줄 수 있음. 근데 그냥 이렇게 하고 끝낼 예정...\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        # ---- 이 fold에서 metrics 계산 ----\n",
    "        # 1) loss / accuracy (evaluate)\n",
    "        loss, acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "        # 2) 예측값 가져와서 precision / f1 (macro) 계산\n",
    "        y_prob = model.predict(X_val, verbose=0)\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "        y_true = y_val\n",
    "\n",
    "        precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        f1        = controller.best_f1\n",
    "        last_f1   = controller.f1_scores[-1]\n",
    "\n",
    "        fold_accuracies.append(acc)\n",
    "        fold_precisions.append(precision)\n",
    "        fold_f1s.append(f1)\n",
    "        fold_last_f1s.append(last_f1)\n",
    "\n",
    "        #now this actually helps\n",
    "        del model\n",
    "        model = None\n",
    "        gc.collect()\n",
    "\n",
    "    # ----- config별 평균/표준편차 정리 -----\n",
    "    cfg_row = {\n",
    "        \"name\": name,\n",
    "        \"acc_mean\":  float(np.mean(fold_accuracies)),\n",
    "        \"acc_std\":   float(np.std(fold_accuracies)),\n",
    "        \"prec_macro_mean\": float(np.mean(fold_precisions)),\n",
    "        \"prec_macro_std\":  float(np.std(fold_precisions)),\n",
    "        \"best_f1_macro_mean\":   float(np.mean(fold_f1s)),\n",
    "        \"best_f1_macro_std\":    float(np.std(fold_f1s)),\n",
    "        \"last_f1_macro_mean\":   float(np.mean(fold_last_f1s)),\n",
    "        \"last_f1_macro_std\":    float(np.std(fold_last_f1s)),\n",
    "    }\n",
    "\n",
    "    print(f\"\\n>>> [CV Summary] {name}: \"\n",
    "          f\"f1_macro={cfg_row['best_f1_macro_mean']:.4f} ± {cfg_row['best_f1_macro_std']:.4f}, \"\n",
    "          f\"last_f1_macro={cfg_row['last_f1_macro_mean']:.4f} ± {cfg_row['last_f1_macro_std']:.4f}, \"\n",
    "          f\"acc={cfg_row['acc_mean']:.4f} ± {cfg_row['acc_std']:.4f}, \")\n",
    "\n",
    "    cv_results.append(cfg_row)\n",
    "    data_index += 1\n",
    "    #print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "XorvY4lmYji3",
   "metadata": {
    "id": "XorvY4lmYji3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-Fold 결과 best_f1_macro_mean DESC\n",
      "     name  acc_mean  acc_std  prec_macro_mean  prec_macro_std  best_f1_macro_mean  best_f1_macro_std  last_f1_macro_mean  last_f1_macro_std\n",
      "id224x336  0.530204 0.015296         0.525065        0.018379            0.515298           0.016560            0.503272           0.012275\n",
      "id256x384  0.515416 0.021094         0.504169        0.022116            0.492634           0.024869            0.484855           0.024319\n",
      "id336x224  0.461210 0.120845         0.468711        0.081118            0.492225           0.012477            0.425649           0.128623\n",
      "id384x256  0.519512 0.019123         0.509456        0.034301            0.490849           0.023655            0.482758           0.027319\n"
     ]
    }
   ],
   "source": [
    "cv_df = pd.DataFrame(cv_results).sort_values(\"best_f1_macro_mean\", ascending=False)\n",
    "print(\"\\nK-Fold 결과 best_f1_macro_mean DESC\")\n",
    "print(cv_df.to_string(index=False))\n",
    "\n",
    "kfold_result_csv_path = DATA_DIR / \"kfold_result_input.csv\"\n",
    "\n",
    "cv_df.to_csv(kfold_result_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32653095-f0e7-4faa-ac0d-8bb49a15b9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (wv-team-venv)",
   "language": "python",
   "name": "wv-team-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02ebafc09f1a4e7ba20e2a1cf9fccfe9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81589a93cdd848358ce75973668acdbc",
      "placeholder": "​",
      "style": "IPY_MODEL_837cd80e9aec4987a0bfe36254a53c4c",
      "value": "Processing Images: 100%"
     }
    },
    "0bf88e29d24f4c1c8da7ca5f681233dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "153e3daeac704ae8bd3a845e761f5c69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_02ebafc09f1a4e7ba20e2a1cf9fccfe9",
       "IPY_MODEL_5087e63df54a4a7aa2c8fdbee60dda43",
       "IPY_MODEL_9b6363585a834d68b424bd09693be95e"
      ],
      "layout": "IPY_MODEL_5a37bae3144f4a5ebc361db1d02ecc15"
     }
    },
    "2c08b7b452be4dff98eb95d8a2aaeb91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5087e63df54a4a7aa2c8fdbee60dda43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c08b7b452be4dff98eb95d8a2aaeb91",
      "max": 3042,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cbcf43f91a824e80aa0745e3cc57e6b3",
      "value": 3042
     }
    },
    "5a37bae3144f4a5ebc361db1d02ecc15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81589a93cdd848358ce75973668acdbc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "837cd80e9aec4987a0bfe36254a53c4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93a9cd26f71f4ff8ac955fcfc8208bef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b6363585a834d68b424bd09693be95e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bf88e29d24f4c1c8da7ca5f681233dc",
      "placeholder": "​",
      "style": "IPY_MODEL_93a9cd26f71f4ff8ac955fcfc8208bef",
      "value": " 3042/3042 [00:29&lt;00:00, 118.56img/s]"
     }
    },
    "cbcf43f91a824e80aa0745e3cc57e6b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
