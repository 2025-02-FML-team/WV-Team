{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bba8009",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/2025-02-FML-team/WV-Team/blob/main/notebooks/05_class_balance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0f7cf03-adc0-4f43-af1e-cd17922b27be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0f7cf03-adc0-4f43-af1e-cd17922b27be",
    "outputId": "f40eaa54-2436-49fe-eb5a-8d115a146fb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Volumes/Backup/Workspace/ML/WV-Team/data')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_DIR = Path('/content/unpacked/')\n",
    "    PACK_DIR = Path('/content/drive/My Drive/colab_drive/prepacked.zip')\n",
    "    shutil.copy(PACK_DIR, '/content/')\n",
    "    !unzip -o -q /content/prepacked.zip -d {DATA_DIR}\n",
    "else:\n",
    "    DATA_DIR= Path(os.path.join(os.getcwd(), \"../data/\")).resolve()\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7puDIfStRQGs",
   "metadata": {
    "id": "7puDIfStRQGs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# CSV 로드 및 정리, 본인 경로에 맞게 변환\n",
    "CSV_PATH = DATA_DIR / 'whiskies_relabel.csv'\n",
    "IMAGE_SIZE = (256, 256)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "tf.random.set_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9zlQt6BNRWMF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "153e3daeac704ae8bd3a845e761f5c69",
      "02ebafc09f1a4e7ba20e2a1cf9fccfe9",
      "5087e63df54a4a7aa2c8fdbee60dda43",
      "9b6363585a834d68b424bd09693be95e",
      "5a37bae3144f4a5ebc361db1d02ecc15",
      "81589a93cdd848358ce75973668acdbc",
      "837cd80e9aec4987a0bfe36254a53c4c",
      "2c08b7b452be4dff98eb95d8a2aaeb91",
      "cbcf43f91a824e80aa0745e3cc57e6b3",
      "0bf88e29d24f4c1c8da7ca5f681233dc",
      "93a9cd26f71f4ff8ac955fcfc8208bef"
     ]
    },
    "id": "9zlQt6BNRWMF",
    "outputId": "5b0b58d4-38bb-475b-c9d5-05ed6e88ce97"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b9923c1bfe40078d4cd94ffce49566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Images:   0%|          | 0/3042 [00:00<?, ?img/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH, dtype={\"id\": str})\n",
    "df[\"id\"] = df[\"id\"].astype(str).str.strip().str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "df[\"category\"] = df[\"category\"].astype(str).str.strip()\n",
    "paths = [DATA_DIR / p for p in df[\"local_full_path\"]]\n",
    "\n",
    "bar = tqdm(paths, desc=\"Processing Images\", unit=\"img\")\n",
    "\n",
    "# 이미지 로드\n",
    "X_list = []\n",
    "for p in bar:\n",
    "    with Image.open(p) as im:\n",
    "        im = im.convert(\"RGB\")\n",
    "        im = im.resize(IMAGE_SIZE)\n",
    "        arr = np.asarray(im, dtype=np.uint8)\n",
    "        X_list.append(arr)\n",
    "X = np.stack(X_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "LZsc1nB0RYSi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZsc1nB0RYSi",
    "outputId": "93df3f32-6828-48ef-95d1-75aa7a36bfd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (2068, 256, 256, 3)\n",
      "X_valid: (517, 256, 256, 3)\n",
      "X_test : (457, 256, 256, 3)\n",
      "y_train 분포: [352 177 104  88  98  93  86 158 174 544  91 103]\n",
      "y_valid 분포: [ 88  44  26  22  24  23  22  39  44 136  23  26]\n",
      "y_test  분포: [ 78  39  23  20  21  21  19  35  38 120  20  23]\n",
      "class mapping: {'Blended': 0, 'Bourbon': 1, 'Brandy': 2, 'Gin': 3, 'Liqueur': 4, 'Rum': 5, 'Rye': 6, 'SM_40_43': 7, 'SM_43_46': 8, 'SM_G46': 9, 'Tequila': 10, 'Vodka': 11}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# 라벨 인코딩\n",
    "labels = df[\"category\"].values\n",
    "le = LabelEncoder()\n",
    "y_int = le.fit_transform(labels)\n",
    "\n",
    "# test 분리\n",
    "X_rest, X_test, y_rest, y_test = train_test_split(\n",
    "    X, y_int,\n",
    "    test_size=0.15,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_int\n",
    ")\n",
    "\n",
    "# train / valid 분리\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_rest, y_rest,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_rest\n",
    ")\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_valid:\", X_valid.shape)\n",
    "print(\"X_test :\", X_test.shape)\n",
    "\n",
    "print(\"y_train 분포:\", np.bincount(y_train))\n",
    "print(\"y_valid 분포:\", np.bincount(y_valid))\n",
    "print(\"y_test  분포:\", np.bincount(y_test))\n",
    "\n",
    "CLASS_NUM = len(le.classes_)\n",
    "print(\"class mapping:\", dict(zip(le.classes_, range(CLASS_NUM))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0t6FOrHAVq0u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0t6FOrHAVq0u",
    "outputId": "d7385606-d271-45d1-a6e7-d2bfd88c9784"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.4895833333333333, 1: 0.9736346516007532, 2: 1.6570512820512822, 3: 1.9583333333333333, 4: 1.7585034013605443, 5: 1.853046594982079, 6: 2.003875968992248, 7: 1.090717299578059, 8: 0.9904214559386973, 9: 0.3167892156862745, 10: 1.8937728937728937, 11: 1.6731391585760518}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.array(range(CLASS_NUM)),\n",
    "    y=y_train,\n",
    ")\n",
    "\n",
    "class_weight_dict = {}\n",
    "\n",
    "i = 0;\n",
    "for weight in class_weights_array:\n",
    "    class_weight_dict[i] = weight\n",
    "    i += 1\n",
    "\n",
    "print(class_weight_dict)\n",
    "# 예: {0: 0.8, 1: 1.2, 2: 3.4, ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0zwOvd67RZPj",
   "metadata": {
    "id": "0zwOvd67RZPj"
   },
   "source": [
    "# 이전의 교훈\n",
    "1. model의 dense layer activation으로 gelu 이용\n",
    "2. batch noramlization 적용\n",
    "\n",
    "# 바꿔야할 것\n",
    "1. 불균형 해소\n",
    "1) other class 분해\\\n",
    "결과 : 여러개의 작은 subclass가 생겨남 노이즈가 줄었을 것이라고 추측\n",
    "2) 부족했던 rye, tequila(라이, 테킬라) 클래스의 샘플을 각각 50개씩 추가(증강)\\\n",
    "결과 : 일단 소수 클래스는 균등해짐 130개 가량...\n",
    "3) class별 weight 부과\\\n",
    "결과 : metric 차이가 있는지는 잘 관찰이 안됨.\n",
    "\n",
    "2. layer 탐색\n",
    "- Dense Layer\\\n",
    "일단 f1 score의 경우 경향성에 있어 차이는 크게 없었지만, score 자체는 0.05+정도 올라온 느낌\n",
    "다른 accuracy나 precision등에 있어서는 경향성의 차이도 생겼는데, 데이터 품질이 개선되어서 그런 것인지는 정확히 모르겠음. 둘 다 균형있게 보는 f1 score를 중심으로 보아 여전히 hl300x2가 좋은 것으로 보임. 다만 같은 2층짜리 구조에서 실험하거나 더 낮은 1층 구조에서 실험하는 것도 가능성이 있어보임.\n",
    "\n",
    "- Conv layer\n",
    "- Input layer\n",
    "- 아마도 input의 경우는 세로가 긴게 연산수를 크게 늘리지 않고서도 좋은 방법이라 사료됨..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a-SqhAtxR-X7",
   "metadata": {
    "id": "a-SqhAtxR-X7"
   },
   "outputs": [],
   "source": [
    "#03 노트북 코드랑 동일함\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, X_val, y_val, start_from_epoch=12, patient=3):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.f1_scores = [] #this is for cumilating f1 per epoch\n",
    "        self.start_from_epoch = start_from_epoch\n",
    "        self.patient = patient\n",
    "        self.out = 0\n",
    "        self.best_f1 = -1\n",
    "\n",
    "    #원래는 GPT가 f1스코어를 넣는 부분만 제공을 하였습니다만, EarlyStopping이 원하는 대로 작동하지 않은 이유로,\n",
    "    #여기서 f1스코어를 계산한후 지속적으로 감지해서 Callback의 명세에 쓰여있는 self.model.stop_training = True\n",
    "    #구문을 사용해서 EarlyStopping과 비슷하게 작동을 정지 시킵니다.\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        if self.y_val.ndim == 2:\n",
    "            y_true = np.argmax(self.y_val, axis=1)\n",
    "        else:\n",
    "            y_true = self.y_val\n",
    "\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        self.f1_scores.append(f1)\n",
    "        logs['val_macro_f1'] = f1\n",
    "\n",
    "        if f1 > self.best_f1:\n",
    "            self.best_f1 = f1\n",
    "\n",
    "        if 1 < epoch and epoch > self.start_from_epoch and f1 < self.f1_scores[-2]:\n",
    "            print(f\"\\nNon Improvement detected at EP : {epoch}, f1 : {f1}\")\n",
    "            self.out += 1\n",
    "\n",
    "        if self.out >= self.patient:\n",
    "            print(f\"\\nStopping at EP : {epoch}, f1 : {f1}\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tfkknavsSKBM",
   "metadata": {
    "id": "tfkknavsSKBM"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.activations import gelu\n",
    "\n",
    "#the name keyword is just there to use kwargs, it's not actually used.\n",
    "def build_model(\n",
    "    hidden=[300, 300],\n",
    "    conv=[32, 64, 128],\n",
    "    conv_double=False,\n",
    "    input_dim=IMAGE_SIZE,\n",
    "    name=\"\"\n",
    "):\n",
    "    inputs = keras.Input(shape=(input_dim[0], input_dim[1], 3)) #근데 이거 조절 할라면 위에서도 바꿔 줘야하지 않나...\n",
    "\n",
    "    x = inputs\n",
    "    for cl in conv:\n",
    "        x = layers.Conv2D(cl, (3,3), activation='relu', padding='same')(x)\n",
    "        if conv_double:\n",
    "            x = layers.Conv2D(cl, (3,3), activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    for hl in hidden:\n",
    "        x = layers.Dense(hl)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('gelu')(x)\n",
    "\n",
    "    outputs = layers.Dense(CLASS_NUM, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ND_KzSUYTUDD",
   "metadata": {
    "id": "ND_KzSUYTUDD"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "configs = [\n",
    "    #hidden layer\n",
    "    {\"name\": \"hl300x2_100x2_50x2\", \"hidden\": [300, 300, 100, 100, 50, 50]},\n",
    "    {\"name\": \"hl100x4\", \"hidden\": [100, 100, 100, 100]},\n",
    "    {\"name\": \"hl300x3\", \"hidden\": [300, 300, 300]},\n",
    "    {\"name\": \"hl300x2\", \"hidden\": [300, 300]},\n",
    "    #later added, less layer seems effective???\n",
    "    {\"name\": \"hl400x2\", \"hidden\": [400, 400]},\n",
    "    {\"name\": \"hl200x2\", \"hidden\": [200, 200]},\n",
    "    {\"name\": \"hl400\", \"hidden\": [400]},\n",
    "    {\"name\": \"hl300\", \"hidden\": [300]},\n",
    "    {\"name\": \"hl200\", \"hidden\": [200]},\n",
    "\n",
    "    #conv layer\n",
    "    {\"name\": \"cl16_32_64\", \"conv\": [16, 32, 64]},\n",
    "    {\"name\": \"cl48_96_192\", \"conv\": [48, 96, 192]},\n",
    "    {\"name\": \"cld16_32_64\", \"conv\": [16, 32, 64], \"conv_double\": True},\n",
    "    {\"name\": \"cld48_96_192\", \"conv\": [48, 96, 192], \"conv_double\": True},\n",
    "\n",
    "    #input layer\n",
    "    {\"name\": \"id320x192\", \"input_dim\": (320, 192)},\n",
    "    {\"name\": \"id288x216\", \"input_dim\": (288, 216)},\n",
    "]\n",
    "\n",
    "cv_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uEESi5nKWhxG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uEESi5nKWhxG",
    "outputId": "217f2c50-8718-443b-d35f-5b9619fe9c0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== K-Fold CV for config: hl400x2 =====\n",
      "\n",
      "[hl400x2] Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 13:54:49.267494: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2025-11-23 13:54:49.269319: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-11-23 13:54:49.269323: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-11-23 13:54:49.271593: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-23 13:54:49.272569: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 13:54:51.081337: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 280ms/step - accuracy: 0.2679 - loss: 2.0913 - val_accuracy: 0.2573 - val_loss: 4.0172 - val_macro_f1: 0.0416\n",
      "Epoch 2/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 259ms/step - accuracy: 0.5846 - loss: 1.1295 - val_accuracy: 0.2108 - val_loss: 3.3981 - val_macro_f1: 0.1122\n",
      "Epoch 3/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 268ms/step - accuracy: 0.8366 - loss: 0.4914 - val_accuracy: 0.1064 - val_loss: 3.5468 - val_macro_f1: 0.0536\n",
      "Epoch 4/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 256ms/step - accuracy: 0.9328 - loss: 0.2435 - val_accuracy: 0.2379 - val_loss: 2.6385 - val_macro_f1: 0.1516\n",
      "Epoch 5/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.9729 - loss: 0.1296 - val_accuracy: 0.2108 - val_loss: 3.2318 - val_macro_f1: 0.1431\n",
      "Epoch 6/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 253ms/step - accuracy: 0.9874 - loss: 0.0766 - val_accuracy: 0.2224 - val_loss: 3.0171 - val_macro_f1: 0.1954\n",
      "Epoch 7/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 252ms/step - accuracy: 0.9932 - loss: 0.0429 - val_accuracy: 0.3985 - val_loss: 2.1630 - val_macro_f1: 0.4206\n",
      "Epoch 8/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 258ms/step - accuracy: 0.9966 - loss: 0.0314 - val_accuracy: 0.3907 - val_loss: 2.3964 - val_macro_f1: 0.4216\n",
      "Epoch 9/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 254ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.5010 - val_loss: 1.7632 - val_macro_f1: 0.4721\n",
      "Epoch 10/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.5319 - val_loss: 1.6475 - val_macro_f1: 0.4949\n",
      "Epoch 11/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 259ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.5571 - val_loss: 1.6481 - val_macro_f1: 0.5156\n",
      "Epoch 12/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 262ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.5571 - val_loss: 1.6702 - val_macro_f1: 0.5217\n",
      "Epoch 13/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 259ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.5571 - val_loss: 1.6918 - val_macro_f1: 0.5223\n",
      "Epoch 14/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 268ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.5571 - val_loss: 1.7110 - val_macro_f1: 0.5255\n",
      "Epoch 15/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 265ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.5551 - val_loss: 1.7257 - val_macro_f1: 0.5200\n",
      "Epoch 16/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 280ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.5571 - val_loss: 1.7384 - val_macro_f1: 0.5213\n",
      "Epoch 17/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 260ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5571 - val_loss: 1.7491 - val_macro_f1: 0.5218\n",
      "Epoch 18/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 1.0000 - loss: 9.5014e-04\n",
      "Non Improvement detected at EP : 17, f1 : 0.5210468428701235\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 9.6470e-04 - val_accuracy: 0.5571 - val_loss: 1.7589 - val_macro_f1: 0.5210\n",
      "Epoch 19/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 276ms/step - accuracy: 1.0000 - loss: 8.7255e-04 - val_accuracy: 0.5571 - val_loss: 1.7677 - val_macro_f1: 0.5210\n",
      "Epoch 20/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 1.0000 - loss: 7.8067e-04\n",
      "Non Improvement detected at EP : 19, f1 : 0.5207355047387731\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 293ms/step - accuracy: 1.0000 - loss: 7.9337e-04 - val_accuracy: 0.5590 - val_loss: 1.7759 - val_macro_f1: 0.5207\n",
      "Epoch 21/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 286ms/step - accuracy: 1.0000 - loss: 7.2456e-04 - val_accuracy: 0.5609 - val_loss: 1.7838 - val_macro_f1: 0.5237\n",
      "Epoch 22/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 296ms/step - accuracy: 1.0000 - loss: 6.6426e-04 - val_accuracy: 0.5590 - val_loss: 1.7917 - val_macro_f1: 0.5248\n",
      "Epoch 23/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 1.0000 - loss: 6.0101e-04\n",
      "Non Improvement detected at EP : 22, f1 : 0.52280034758441\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 278ms/step - accuracy: 1.0000 - loss: 6.1111e-04 - val_accuracy: 0.5571 - val_loss: 1.7987 - val_macro_f1: 0.5228\n",
      "Epoch 24/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 1.0000 - loss: 5.5454e-04\n",
      "Non Improvement detected at EP : 23, f1 : 0.5192985021361339\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 280ms/step - accuracy: 1.0000 - loss: 5.6394e-04 - val_accuracy: 0.5551 - val_loss: 1.8051 - val_macro_f1: 0.5193\n",
      "Epoch 25/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 266ms/step - accuracy: 1.0000 - loss: 5.2180e-04 - val_accuracy: 0.5551 - val_loss: 1.8118 - val_macro_f1: 0.5193\n",
      "Epoch 26/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 270ms/step - accuracy: 1.0000 - loss: 4.8402e-04 - val_accuracy: 0.5571 - val_loss: 1.8179 - val_macro_f1: 0.5227\n",
      "Epoch 27/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 272ms/step - accuracy: 1.0000 - loss: 4.4996e-04 - val_accuracy: 0.5590 - val_loss: 1.8243 - val_macro_f1: 0.5244\n",
      "Epoch 28/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 271ms/step - accuracy: 1.0000 - loss: 4.1916e-04 - val_accuracy: 0.5590 - val_loss: 1.8303 - val_macro_f1: 0.5248\n",
      "Epoch 29/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 1.0000 - loss: 3.8450e-04\n",
      "Non Improvement detected at EP : 28, f1 : 0.5231259815403592\n",
      "\n",
      "Stopping at EP : 28, f1 : 0.5231259815403592\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 278ms/step - accuracy: 1.0000 - loss: 3.9116e-04 - val_accuracy: 0.5571 - val_loss: 1.8358 - val_macro_f1: 0.5231\n",
      "[hl400x2] Fold 1: loss=1.8358, acc=0.5571, prec_macro=0.5505, f1_macro=0.5255\n",
      "\n",
      "[hl400x2] Fold 2/5\n",
      "Epoch 1/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 322ms/step - accuracy: 0.2398 - loss: 2.1452 - val_accuracy: 0.1431 - val_loss: 3.4282 - val_macro_f1: 0.0499\n",
      "Epoch 2/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 282ms/step - accuracy: 0.5430 - loss: 1.2428 - val_accuracy: 0.3250 - val_loss: 2.4582 - val_macro_f1: 0.1368\n",
      "Epoch 3/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 289ms/step - accuracy: 0.7887 - loss: 0.5897 - val_accuracy: 0.2901 - val_loss: 2.5211 - val_macro_f1: 0.1231\n",
      "Epoch 4/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 297ms/step - accuracy: 0.9275 - loss: 0.2551 - val_accuracy: 0.3385 - val_loss: 2.8064 - val_macro_f1: 0.1666\n",
      "Epoch 5/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 291ms/step - accuracy: 0.9753 - loss: 0.1301 - val_accuracy: 0.3714 - val_loss: 2.3774 - val_macro_f1: 0.2434\n",
      "Epoch 6/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 306ms/step - accuracy: 0.9865 - loss: 0.0749 - val_accuracy: 0.3327 - val_loss: 2.5777 - val_macro_f1: 0.2309\n",
      "Epoch 7/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 292ms/step - accuracy: 0.9918 - loss: 0.0450 - val_accuracy: 0.4159 - val_loss: 2.2050 - val_macro_f1: 0.2776\n",
      "Epoch 8/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 288ms/step - accuracy: 0.9966 - loss: 0.0290 - val_accuracy: 0.4120 - val_loss: 1.9533 - val_macro_f1: 0.3553\n",
      "Epoch 9/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 363ms/step - accuracy: 0.9990 - loss: 0.0184 - val_accuracy: 0.3462 - val_loss: 2.4664 - val_macro_f1: 0.3549\n",
      "Epoch 10/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 303ms/step - accuracy: 0.9990 - loss: 0.0131 - val_accuracy: 0.4081 - val_loss: 2.3161 - val_macro_f1: 0.4152\n",
      "Epoch 11/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 317ms/step - accuracy: 0.9995 - loss: 0.0088 - val_accuracy: 0.5416 - val_loss: 1.7105 - val_macro_f1: 0.4930\n",
      "Epoch 12/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.5532 - val_loss: 1.7025 - val_macro_f1: 0.5116\n",
      "Epoch 13/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 343ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.5590 - val_loss: 1.7214 - val_macro_f1: 0.5193\n",
      "Epoch 14/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.5590 - val_loss: 1.7376 - val_macro_f1: 0.5226\n",
      "Epoch 15/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.5551 - val_loss: 1.7529 - val_macro_f1: 0.5183\n",
      "Epoch 16/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 297ms/step - accuracy: 1.0000 - loss: 9.7272e-04 - val_accuracy: 0.5474 - val_loss: 1.7754 - val_macro_f1: 0.5081\n",
      "Epoch 17/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 286ms/step - accuracy: 1.0000 - loss: 7.9339e-04 - val_accuracy: 0.5493 - val_loss: 1.8016 - val_macro_f1: 0.5115\n",
      "Epoch 18/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 1.0000 - loss: 6.7118e-04\n",
      "Non Improvement detected at EP : 17, f1 : 0.5086696727006075\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 6.5205e-04 - val_accuracy: 0.5455 - val_loss: 1.8282 - val_macro_f1: 0.5087\n",
      "Epoch 19/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 5.4184e-04 - val_accuracy: 0.5455 - val_loss: 1.8542 - val_macro_f1: 0.5094\n",
      "Epoch 20/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 4.5649e-04 - val_accuracy: 0.5474 - val_loss: 1.8789 - val_macro_f1: 0.5101\n",
      "Epoch 21/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 1.0000 - loss: 4.0049e-04\n",
      "Non Improvement detected at EP : 20, f1 : 0.5076595422870177\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 3.9010e-04 - val_accuracy: 0.5435 - val_loss: 1.9019 - val_macro_f1: 0.5077\n",
      "Epoch 22/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 1.0000 - loss: 3.4645e-04\n",
      "Non Improvement detected at EP : 21, f1 : 0.505850857902426\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 299ms/step - accuracy: 1.0000 - loss: 3.3776e-04 - val_accuracy: 0.5416 - val_loss: 1.9243 - val_macro_f1: 0.5059\n",
      "Epoch 23/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 284ms/step - accuracy: 1.0000 - loss: 2.9591e-04 - val_accuracy: 0.5435 - val_loss: 1.9449 - val_macro_f1: 0.5093\n",
      "Epoch 24/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 287ms/step - accuracy: 1.0000 - loss: 2.6191e-04 - val_accuracy: 0.5455 - val_loss: 1.9645 - val_macro_f1: 0.5117\n",
      "Epoch 25/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 1.0000 - loss: 2.3926e-04\n",
      "Non Improvement detected at EP : 24, f1 : 0.5089787271194054\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 287ms/step - accuracy: 1.0000 - loss: 2.3388e-04 - val_accuracy: 0.5435 - val_loss: 1.9833 - val_macro_f1: 0.5090\n",
      "Epoch 26/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 280ms/step - accuracy: 1.0000 - loss: 2.1048e-04 - val_accuracy: 0.5455 - val_loss: 2.0003 - val_macro_f1: 0.5098\n",
      "Epoch 27/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 280ms/step - accuracy: 1.0000 - loss: 1.9071e-04 - val_accuracy: 0.5474 - val_loss: 2.0164 - val_macro_f1: 0.5103\n",
      "Epoch 28/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 1.0000 - loss: 1.7750e-04\n",
      "Non Improvement detected at EP : 27, f1 : 0.5102062026371451\n",
      "\n",
      "Stopping at EP : 27, f1 : 0.5102062026371451\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 279ms/step - accuracy: 1.0000 - loss: 1.7385e-04 - val_accuracy: 0.5474 - val_loss: 2.0305 - val_macro_f1: 0.5102\n",
      "[hl400x2] Fold 2: loss=2.0305, acc=0.5474, prec_macro=0.5519, f1_macro=0.5226\n",
      "\n",
      "[hl400x2] Fold 3/5\n",
      "Epoch 1/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 301ms/step - accuracy: 0.2814 - loss: 2.1213 - val_accuracy: 0.2108 - val_loss: 4.1979 - val_macro_f1: 0.0524\n",
      "Epoch 2/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 315ms/step - accuracy: 0.5474 - loss: 1.2355 - val_accuracy: 0.0909 - val_loss: 3.9579 - val_macro_f1: 0.0720\n",
      "Epoch 3/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 332ms/step - accuracy: 0.8085 - loss: 0.5852 - val_accuracy: 0.2224 - val_loss: 3.0275 - val_macro_f1: 0.1242\n",
      "Epoch 4/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 350ms/step - accuracy: 0.9139 - loss: 0.3145 - val_accuracy: 0.3327 - val_loss: 2.9090 - val_macro_f1: 0.1567\n",
      "Epoch 5/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 357ms/step - accuracy: 0.9463 - loss: 0.2117 - val_accuracy: 0.2882 - val_loss: 3.4796 - val_macro_f1: 0.1547\n",
      "Epoch 6/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 350ms/step - accuracy: 0.9628 - loss: 0.1549 - val_accuracy: 0.2089 - val_loss: 3.6893 - val_macro_f1: 0.1773\n",
      "Epoch 7/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 381ms/step - accuracy: 0.9821 - loss: 0.0752 - val_accuracy: 0.3346 - val_loss: 2.3086 - val_macro_f1: 0.2813\n",
      "Epoch 8/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 385ms/step - accuracy: 0.9898 - loss: 0.0512 - val_accuracy: 0.2224 - val_loss: 2.9925 - val_macro_f1: 0.1777\n",
      "Epoch 9/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 352ms/step - accuracy: 0.9952 - loss: 0.0268 - val_accuracy: 0.3230 - val_loss: 2.2076 - val_macro_f1: 0.2780\n",
      "Epoch 10/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 332ms/step - accuracy: 0.9995 - loss: 0.0111 - val_accuracy: 0.4797 - val_loss: 1.7527 - val_macro_f1: 0.4627\n",
      "Epoch 11/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 326ms/step - accuracy: 0.9981 - loss: 0.0130 - val_accuracy: 0.5048 - val_loss: 1.8003 - val_macro_f1: 0.4832\n",
      "Epoch 12/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 375ms/step - accuracy: 0.9995 - loss: 0.0077 - val_accuracy: 0.4855 - val_loss: 1.7955 - val_macro_f1: 0.4759\n",
      "Epoch 13/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 376ms/step - accuracy: 0.9990 - loss: 0.0074 - val_accuracy: 0.4487 - val_loss: 1.8734 - val_macro_f1: 0.4384\n",
      "Epoch 14/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 365ms/step - accuracy: 0.9995 - loss: 0.0055 - val_accuracy: 0.4894 - val_loss: 1.7861 - val_macro_f1: 0.4879\n",
      "Epoch 15/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 353ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.4990 - val_loss: 1.8014 - val_macro_f1: 0.4839\n",
      "Epoch 16/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 343ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.5106 - val_loss: 1.8319 - val_macro_f1: 0.4908\n",
      "Epoch 17/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 358ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.5184 - val_loss: 1.8617 - val_macro_f1: 0.4980\n",
      "Epoch 18/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 328ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.5184 - val_loss: 1.8868 - val_macro_f1: 0.4999\n",
      "Epoch 19/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Non Improvement detected at EP : 18, f1 : 0.49355952716526813\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.5126 - val_loss: 1.9075 - val_macro_f1: 0.4936\n",
      "Epoch 20/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.5145 - val_loss: 1.9252 - val_macro_f1: 0.4945\n",
      "Epoch 21/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 9.3275e-04 - val_accuracy: 0.5164 - val_loss: 1.9399 - val_macro_f1: 0.4970\n",
      "Epoch 22/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 373ms/step - accuracy: 1.0000 - loss: 8.4785e-04 - val_accuracy: 0.5184 - val_loss: 1.9532 - val_macro_f1: 0.4987\n",
      "Epoch 23/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 342ms/step - accuracy: 1.0000 - loss: 7.7455e-04 - val_accuracy: 0.5184 - val_loss: 1.9650 - val_macro_f1: 0.4987\n",
      "Epoch 24/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 328ms/step - accuracy: 1.0000 - loss: 7.1050e-04 - val_accuracy: 0.5203 - val_loss: 1.9747 - val_macro_f1: 0.5002\n",
      "Epoch 25/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 7.3926e-04\n",
      "Non Improvement detected at EP : 24, f1 : 0.4989161329537164\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 334ms/step - accuracy: 1.0000 - loss: 6.5395e-04 - val_accuracy: 0.5184 - val_loss: 1.9847 - val_macro_f1: 0.4989\n",
      "Epoch 26/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 6.0375e-04 - val_accuracy: 0.5184 - val_loss: 1.9944 - val_macro_f1: 0.4989\n",
      "Epoch 27/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 6.2938e-04\n",
      "Non Improvement detected at EP : 26, f1 : 0.49599983557713606\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 357ms/step - accuracy: 1.0000 - loss: 5.5890e-04 - val_accuracy: 0.5164 - val_loss: 2.0034 - val_macro_f1: 0.4960\n",
      "Epoch 28/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 353ms/step - accuracy: 1.0000 - loss: 5.1857e-04 - val_accuracy: 0.5184 - val_loss: 2.0122 - val_macro_f1: 0.4991\n",
      "Epoch 29/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 350ms/step - accuracy: 1.0000 - loss: 4.8207e-04 - val_accuracy: 0.5184 - val_loss: 2.0207 - val_macro_f1: 0.4991\n",
      "Epoch 30/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 5.0338e-04\n",
      "Non Improvement detected at EP : 29, f1 : 0.49869428519696685\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 333ms/step - accuracy: 1.0000 - loss: 4.4892e-04 - val_accuracy: 0.5184 - val_loss: 2.0291 - val_macro_f1: 0.4987\n",
      "Epoch 31/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 333ms/step - accuracy: 1.0000 - loss: 4.1867e-04 - val_accuracy: 0.5203 - val_loss: 2.0375 - val_macro_f1: 0.4995\n",
      "Epoch 32/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 1.0000 - loss: 4.3761e-04\n",
      "Non Improvement detected at EP : 31, f1 : 0.4992849909448159\n",
      "\n",
      "Stopping at EP : 31, f1 : 0.4992849909448159\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 3.9104e-04 - val_accuracy: 0.5203 - val_loss: 2.0458 - val_macro_f1: 0.4993\n",
      "[hl400x2] Fold 3: loss=2.0458, acc=0.5203, prec_macro=0.5143, f1_macro=0.5002\n",
      "\n",
      "[hl400x2] Fold 4/5\n",
      "Epoch 1/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 336ms/step - accuracy: 0.2631 - loss: 2.0765 - val_accuracy: 0.3617 - val_loss: 2.4889 - val_macro_f1: 0.1132\n",
      "Epoch 2/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 374ms/step - accuracy: 0.5358 - loss: 1.2072 - val_accuracy: 0.1431 - val_loss: 3.3731 - val_macro_f1: 0.0813\n",
      "Epoch 3/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 401ms/step - accuracy: 0.7756 - loss: 0.6037 - val_accuracy: 0.2050 - val_loss: 3.2663 - val_macro_f1: 0.1055\n",
      "Epoch 4/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 381ms/step - accuracy: 0.9110 - loss: 0.2920 - val_accuracy: 0.2495 - val_loss: 2.6710 - val_macro_f1: 0.1795\n",
      "Epoch 5/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 338ms/step - accuracy: 0.9618 - loss: 0.1645 - val_accuracy: 0.2766 - val_loss: 4.0409 - val_macro_f1: 0.0676\n",
      "Epoch 6/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 322ms/step - accuracy: 0.9729 - loss: 0.1093 - val_accuracy: 0.2418 - val_loss: 2.9269 - val_macro_f1: 0.1664\n",
      "Epoch 7/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 326ms/step - accuracy: 0.9865 - loss: 0.0764 - val_accuracy: 0.2863 - val_loss: 4.2170 - val_macro_f1: 0.1532\n",
      "Epoch 8/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 333ms/step - accuracy: 0.9889 - loss: 0.0505 - val_accuracy: 0.2437 - val_loss: 4.6290 - val_macro_f1: 0.1413\n",
      "Epoch 9/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 331ms/step - accuracy: 0.9966 - loss: 0.0332 - val_accuracy: 0.4004 - val_loss: 2.1699 - val_macro_f1: 0.3621\n",
      "Epoch 10/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 332ms/step - accuracy: 0.9971 - loss: 0.0171 - val_accuracy: 0.4410 - val_loss: 1.9857 - val_macro_f1: 0.4056\n",
      "Epoch 11/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 330ms/step - accuracy: 0.9981 - loss: 0.0242 - val_accuracy: 0.3965 - val_loss: 2.0721 - val_macro_f1: 0.3441\n",
      "Epoch 12/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 329ms/step - accuracy: 0.9985 - loss: 0.0084 - val_accuracy: 0.4739 - val_loss: 1.9412 - val_macro_f1: 0.4247\n",
      "Epoch 13/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 330ms/step - accuracy: 0.9990 - loss: 0.0074 - val_accuracy: 0.5087 - val_loss: 1.6935 - val_macro_f1: 0.4393\n",
      "Epoch 14/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 325ms/step - accuracy: 0.9995 - loss: 0.0064 - val_accuracy: 0.5126 - val_loss: 1.7542 - val_macro_f1: 0.4593\n",
      "Epoch 15/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 338ms/step - accuracy: 0.9995 - loss: 0.0048 - val_accuracy: 0.5300 - val_loss: 1.7132 - val_macro_f1: 0.4824\n",
      "Epoch 16/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 352ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.5416 - val_loss: 1.6996 - val_macro_f1: 0.4875\n",
      "Epoch 17/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Non Improvement detected at EP : 16, f1 : 0.481506475125191\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.5397 - val_loss: 1.7084 - val_macro_f1: 0.4815\n",
      "Epoch 18/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 369ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.5416 - val_loss: 1.7195 - val_macro_f1: 0.4870\n",
      "Epoch 19/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 364ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5416 - val_loss: 1.7325 - val_macro_f1: 0.4924\n",
      "Epoch 20/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 9.7840e-04 - val_accuracy: 0.5455 - val_loss: 1.7452 - val_macro_f1: 0.5000\n",
      "Epoch 21/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 357ms/step - accuracy: 1.0000 - loss: 8.7990e-04 - val_accuracy: 0.5455 - val_loss: 1.7571 - val_macro_f1: 0.5000\n",
      "Epoch 22/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 348ms/step - accuracy: 1.0000 - loss: 7.9788e-04 - val_accuracy: 0.5474 - val_loss: 1.7676 - val_macro_f1: 0.5004\n",
      "Epoch 23/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 374ms/step - accuracy: 1.0000 - loss: 7.2825e-04 - val_accuracy: 0.5493 - val_loss: 1.7767 - val_macro_f1: 0.5029\n",
      "Epoch 24/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 357ms/step - accuracy: 1.0000 - loss: 6.6822e-04 - val_accuracy: 0.5513 - val_loss: 1.7850 - val_macro_f1: 0.5029\n",
      "Epoch 25/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - accuracy: 1.0000 - loss: 6.3455e-04\n",
      "Non Improvement detected at EP : 24, f1 : 0.5025927666726081\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 365ms/step - accuracy: 1.0000 - loss: 6.1584e-04 - val_accuracy: 0.5513 - val_loss: 1.7927 - val_macro_f1: 0.5026\n",
      "Epoch 26/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 360ms/step - accuracy: 1.0000 - loss: 5.6972e-04 - val_accuracy: 0.5513 - val_loss: 1.7998 - val_macro_f1: 0.5027\n",
      "Epoch 27/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 378ms/step - accuracy: 1.0000 - loss: 5.2878e-04 - val_accuracy: 0.5513 - val_loss: 1.8064 - val_macro_f1: 0.5027\n",
      "Epoch 28/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 390ms/step - accuracy: 1.0000 - loss: 4.9217e-04 - val_accuracy: 0.5532 - val_loss: 1.8126 - val_macro_f1: 0.5036\n",
      "Epoch 29/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 369ms/step - accuracy: 1.0000 - loss: 4.5926e-04 - val_accuracy: 0.5532 - val_loss: 1.8182 - val_macro_f1: 0.5036\n",
      "Epoch 30/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 400ms/step - accuracy: 1.0000 - loss: 4.2949e-04 - val_accuracy: 0.5551 - val_loss: 1.8237 - val_macro_f1: 0.5069\n",
      "Epoch 31/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 4.0243e-04 - val_accuracy: 0.5571 - val_loss: 1.8291 - val_macro_f1: 0.5078\n",
      "Epoch 32/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 385ms/step - accuracy: 1.0000 - loss: 3.7777e-04 - val_accuracy: 0.5571 - val_loss: 1.8342 - val_macro_f1: 0.5078\n",
      "Epoch 33/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 393ms/step - accuracy: 1.0000 - loss: 3.5521e-04 - val_accuracy: 0.5590 - val_loss: 1.8390 - val_macro_f1: 0.5116\n",
      "Epoch 34/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 376ms/step - accuracy: 1.0000 - loss: 3.3449e-04 - val_accuracy: 0.5590 - val_loss: 1.8436 - val_macro_f1: 0.5116\n",
      "Epoch 35/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 373ms/step - accuracy: 1.0000 - loss: 3.1539e-04 - val_accuracy: 0.5609 - val_loss: 1.8482 - val_macro_f1: 0.5160\n",
      "Epoch 36/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 3.0408e-04\n",
      "Non Improvement detected at EP : 35, f1 : 0.5158908847020266\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 357ms/step - accuracy: 1.0000 - loss: 2.9776e-04 - val_accuracy: 0.5609 - val_loss: 1.8501 - val_macro_f1: 0.5159\n",
      "Epoch 37/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 2.8728e-04\n",
      "Non Improvement detected at EP : 36, f1 : 0.5145021051615523\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 347ms/step - accuracy: 1.0000 - loss: 2.8140e-04 - val_accuracy: 0.5609 - val_loss: 1.8551 - val_macro_f1: 0.5145\n",
      "Epoch 38/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 2.7169e-04\n",
      "Non Improvement detected at EP : 37, f1 : 0.5137166020962873\n",
      "\n",
      "Stopping at EP : 37, f1 : 0.5137166020962873\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 350ms/step - accuracy: 1.0000 - loss: 2.6623e-04 - val_accuracy: 0.5609 - val_loss: 1.8593 - val_macro_f1: 0.5137\n",
      "[hl400x2] Fold 4: loss=1.8593, acc=0.5609, prec_macro=0.5385, f1_macro=0.5160\n",
      "\n",
      "[hl400x2] Fold 5/5\n",
      "Epoch 1/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 376ms/step - accuracy: 0.2756 - loss: 2.0633 - val_accuracy: 0.1876 - val_loss: 2.8208 - val_macro_f1: 0.0707\n",
      "Epoch 2/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 427ms/step - accuracy: 0.6339 - loss: 0.9986 - val_accuracy: 0.1915 - val_loss: 3.1254 - val_macro_f1: 0.0960\n",
      "Epoch 3/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 398ms/step - accuracy: 0.8830 - loss: 0.3823 - val_accuracy: 0.1199 - val_loss: 3.7038 - val_macro_f1: 0.0790\n",
      "Epoch 4/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 399ms/step - accuracy: 0.9637 - loss: 0.1541 - val_accuracy: 0.1180 - val_loss: 3.8823 - val_macro_f1: 0.0618\n",
      "Epoch 5/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 394ms/step - accuracy: 0.9836 - loss: 0.0882 - val_accuracy: 0.2979 - val_loss: 2.5895 - val_macro_f1: 0.1409\n",
      "Epoch 6/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 377ms/step - accuracy: 0.9913 - loss: 0.0549 - val_accuracy: 0.3017 - val_loss: 2.5537 - val_macro_f1: 0.2413\n",
      "Epoch 7/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 356ms/step - accuracy: 0.9937 - loss: 0.0443 - val_accuracy: 0.4371 - val_loss: 2.3226 - val_macro_f1: 0.3247\n",
      "Epoch 8/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 389ms/step - accuracy: 0.9923 - loss: 0.0380 - val_accuracy: 0.4004 - val_loss: 2.3913 - val_macro_f1: 0.3625\n",
      "Epoch 9/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 375ms/step - accuracy: 0.9952 - loss: 0.0264 - val_accuracy: 0.4836 - val_loss: 1.7703 - val_macro_f1: 0.4475\n",
      "Epoch 10/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 386ms/step - accuracy: 0.9990 - loss: 0.0104 - val_accuracy: 0.4836 - val_loss: 1.8041 - val_macro_f1: 0.4676\n",
      "Epoch 11/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 371ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.5048 - val_loss: 1.6805 - val_macro_f1: 0.4894\n",
      "Epoch 12/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.5203 - val_loss: 1.7083 - val_macro_f1: 0.4994\n",
      "Epoch 13/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 384ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.5222 - val_loss: 1.7498 - val_macro_f1: 0.4993\n",
      "Epoch 14/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 390ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.5203 - val_loss: 1.7860 - val_macro_f1: 0.4983\n",
      "Epoch 15/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 346ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5242 - val_loss: 1.8144 - val_macro_f1: 0.5021\n",
      "Epoch 16/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 342ms/step - accuracy: 1.0000 - loss: 9.8807e-04 - val_accuracy: 0.5222 - val_loss: 1.8365 - val_macro_f1: 0.4999\n",
      "Epoch 17/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 9.6257e-04\n",
      "Non Improvement detected at EP : 16, f1 : 0.49688951049614244\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 351ms/step - accuracy: 1.0000 - loss: 8.7496e-04 - val_accuracy: 0.5222 - val_loss: 1.8558 - val_macro_f1: 0.4969\n",
      "Epoch 18/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - accuracy: 1.0000 - loss: 8.5722e-04\n",
      "Non Improvement detected at EP : 17, f1 : 0.4953630406389782\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 371ms/step - accuracy: 1.0000 - loss: 7.8134e-04 - val_accuracy: 0.5203 - val_loss: 1.8715 - val_macro_f1: 0.4954\n",
      "Epoch 19/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - accuracy: 1.0000 - loss: 7.6811e-04\n",
      "Non Improvement detected at EP : 18, f1 : 0.4951768950294824\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 375ms/step - accuracy: 1.0000 - loss: 7.0180e-04 - val_accuracy: 0.5203 - val_loss: 1.8856 - val_macro_f1: 0.4952\n",
      "Epoch 20/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 377ms/step - accuracy: 1.0000 - loss: 6.3252e-04 - val_accuracy: 0.5222 - val_loss: 1.8982 - val_macro_f1: 0.4994\n",
      "Epoch 21/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 366ms/step - accuracy: 1.0000 - loss: 5.7063e-04 - val_accuracy: 0.5222 - val_loss: 1.9103 - val_macro_f1: 0.4994\n",
      "Epoch 22/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 406ms/step - accuracy: 1.0000 - loss: 5.1401e-04 - val_accuracy: 0.5242 - val_loss: 1.9220 - val_macro_f1: 0.5008\n",
      "Epoch 23/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 5.0178e-04\n",
      "Non Improvement detected at EP : 22, f1 : 0.49989980482819685\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 4.6119e-04 - val_accuracy: 0.5222 - val_loss: 1.9346 - val_macro_f1: 0.4999\n",
      "Epoch 24/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 4.4762e-04\n",
      "Non Improvement detected at EP : 23, f1 : 0.4977086270556224\n",
      "\n",
      "Stopping at EP : 23, f1 : 0.4977086270556224\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 4.1161e-04 - val_accuracy: 0.5203 - val_loss: 1.9471 - val_macro_f1: 0.4977\n",
      "[hl400x2] Fold 5: loss=1.9471, acc=0.5203, prec_macro=0.5282, f1_macro=0.5021\n",
      "\n",
      ">>> [CV Summary] hl400x2: f1_macro=0.5133 ± 0.0104, last_f1_macro=0.5088 ± 0.0094, acc=0.5412 ± 0.0176, \n",
      "[{'name': 'hl400x2', 'acc_mean': 0.5411992073059082, 'acc_std': 0.017617486767983446, 'prec_macro_mean': 0.536675582607156, 'prec_macro_std': 0.014122488884678219, 'best_f1_macro_mean': 0.5132893574467529, 'best_f1_macro_std': 0.010373767316101862, 'last_f1_macro_mean': 0.508808480854846, 'last_f1_macro_std': 0.009433320948760884}]\n",
      "\n",
      "===== K-Fold CV for config: hl200x2 =====\n",
      "\n",
      "[hl200x2] Fold 1/5\n",
      "Epoch 1/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 323ms/step - accuracy: 0.2582 - loss: 2.0681 - val_accuracy: 0.2263 - val_loss: 2.7784 - val_macro_f1: 0.0856\n",
      "Epoch 2/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 331ms/step - accuracy: 0.5754 - loss: 1.1909 - val_accuracy: 0.1779 - val_loss: 2.8831 - val_macro_f1: 0.0738\n",
      "Epoch 3/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 315ms/step - accuracy: 0.8046 - loss: 0.6281 - val_accuracy: 0.2321 - val_loss: 3.2880 - val_macro_f1: 0.1273\n",
      "Epoch 4/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 328ms/step - accuracy: 0.9081 - loss: 0.3249 - val_accuracy: 0.2244 - val_loss: 2.4175 - val_macro_f1: 0.1707\n",
      "Epoch 5/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 309ms/step - accuracy: 0.9657 - loss: 0.1672 - val_accuracy: 0.1934 - val_loss: 2.9429 - val_macro_f1: 0.1849\n",
      "Epoch 6/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 302ms/step - accuracy: 0.9802 - loss: 0.1015 - val_accuracy: 0.4004 - val_loss: 2.6516 - val_macro_f1: 0.2722\n",
      "Epoch 7/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 312ms/step - accuracy: 0.9913 - loss: 0.0661 - val_accuracy: 0.3153 - val_loss: 2.2566 - val_macro_f1: 0.3392\n",
      "Epoch 8/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 310ms/step - accuracy: 0.9961 - loss: 0.0374 - val_accuracy: 0.2476 - val_loss: 2.4686 - val_macro_f1: 0.2297\n",
      "Epoch 9/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 332ms/step - accuracy: 0.9966 - loss: 0.0287 - val_accuracy: 0.1083 - val_loss: 5.9771 - val_macro_f1: 0.0795\n",
      "Epoch 10/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 308ms/step - accuracy: 0.9981 - loss: 0.0208 - val_accuracy: 0.3965 - val_loss: 2.0911 - val_macro_f1: 0.4183\n",
      "Epoch 11/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 297ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.5087 - val_loss: 1.7504 - val_macro_f1: 0.5047\n",
      "Epoch 12/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.5242 - val_loss: 1.6650 - val_macro_f1: 0.5061\n",
      "Epoch 13/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.5377 - val_loss: 1.6580 - val_macro_f1: 0.5085\n",
      "Epoch 14/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 291ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.5455 - val_loss: 1.6683 - val_macro_f1: 0.5218\n",
      "Epoch 15/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 288ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.5435 - val_loss: 1.6823 - val_macro_f1: 0.5195\n",
      "Epoch 16/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 296ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.5474 - val_loss: 1.6959 - val_macro_f1: 0.5246\n",
      "Epoch 17/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Non Improvement detected at EP : 16, f1 : 0.5203762914741504\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 299ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.5474 - val_loss: 1.7086 - val_macro_f1: 0.5204\n",
      "Epoch 18/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Non Improvement detected at EP : 17, f1 : 0.5191482416224599\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.5474 - val_loss: 1.7200 - val_macro_f1: 0.5191\n",
      "Epoch 19/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 286ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.5474 - val_loss: 1.7300 - val_macro_f1: 0.5208\n",
      "Epoch 20/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Non Improvement detected at EP : 19, f1 : 0.520426942505018\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 288ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.5474 - val_loss: 1.7392 - val_macro_f1: 0.5204\n",
      "Epoch 21/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.5532 - val_loss: 1.7475 - val_macro_f1: 0.5289\n",
      "Epoch 22/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 276ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.5532 - val_loss: 1.7554 - val_macro_f1: 0.5297\n",
      "Epoch 23/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 277ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.5590 - val_loss: 1.7627 - val_macro_f1: 0.5386\n",
      "Epoch 24/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 299ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.5590 - val_loss: 1.7694 - val_macro_f1: 0.5386\n",
      "Epoch 25/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 294ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5571 - val_loss: 1.7768 - val_macro_f1: 0.5388\n",
      "Epoch 26/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 279ms/step - accuracy: 1.0000 - loss: 9.8657e-04 - val_accuracy: 0.5571 - val_loss: 1.7839 - val_macro_f1: 0.5403\n",
      "Epoch 27/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 330ms/step - accuracy: 1.0000 - loss: 9.1718e-04 - val_accuracy: 0.5571 - val_loss: 1.7898 - val_macro_f1: 0.5403\n",
      "Epoch 28/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 1.0000 - loss: 8.5509e-04\n",
      "Non Improvement detected at EP : 27, f1 : 0.5401956926105727\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 296ms/step - accuracy: 1.0000 - loss: 8.5457e-04 - val_accuracy: 0.5571 - val_loss: 1.7957 - val_macro_f1: 0.5402\n",
      "Epoch 29/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 7.9783e-04 - val_accuracy: 0.5571 - val_loss: 1.8017 - val_macro_f1: 0.5402\n",
      "Epoch 30/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 295ms/step - accuracy: 1.0000 - loss: 7.4619e-04 - val_accuracy: 0.5571 - val_loss: 1.8075 - val_macro_f1: 0.5402\n",
      "Epoch 31/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 6.9906e-04 - val_accuracy: 0.5590 - val_loss: 1.8131 - val_macro_f1: 0.5408\n",
      "Epoch 32/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 297ms/step - accuracy: 1.0000 - loss: 6.5594e-04 - val_accuracy: 0.5590 - val_loss: 1.8184 - val_macro_f1: 0.5408\n",
      "Epoch 33/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 1.0000 - loss: 6.1515e-04\n",
      "Non Improvement detected at EP : 32, f1 : 0.5381679952902974\n",
      "\n",
      "Stopping at EP : 32, f1 : 0.5381679952902974\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 299ms/step - accuracy: 1.0000 - loss: 6.1637e-04 - val_accuracy: 0.5571 - val_loss: 1.8244 - val_macro_f1: 0.5382\n",
      "[hl200x2] Fold 1: loss=1.8244, acc=0.5571, prec_macro=0.5616, f1_macro=0.5408\n",
      "\n",
      "[hl200x2] Fold 2/5\n",
      "Epoch 1/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 337ms/step - accuracy: 0.2597 - loss: 2.1193 - val_accuracy: 0.1025 - val_loss: 3.6627 - val_macro_f1: 0.0882\n",
      "Epoch 2/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 336ms/step - accuracy: 0.5237 - loss: 1.2807 - val_accuracy: 0.1335 - val_loss: 3.5769 - val_macro_f1: 0.0526\n",
      "Epoch 3/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 325ms/step - accuracy: 0.7911 - loss: 0.6244 - val_accuracy: 0.1393 - val_loss: 2.9701 - val_macro_f1: 0.0656\n",
      "Epoch 4/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 319ms/step - accuracy: 0.9270 - loss: 0.2945 - val_accuracy: 0.3153 - val_loss: 2.1520 - val_macro_f1: 0.1882\n",
      "Epoch 5/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 310ms/step - accuracy: 0.9662 - loss: 0.1562 - val_accuracy: 0.2766 - val_loss: 2.1810 - val_macro_f1: 0.1652\n",
      "Epoch 6/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 288ms/step - accuracy: 0.9884 - loss: 0.0926 - val_accuracy: 0.2263 - val_loss: 2.5672 - val_macro_f1: 0.2028\n",
      "Epoch 7/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 293ms/step - accuracy: 0.9956 - loss: 0.0644 - val_accuracy: 0.2689 - val_loss: 3.0375 - val_macro_f1: 0.2122\n",
      "Epoch 8/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 293ms/step - accuracy: 0.9971 - loss: 0.0331 - val_accuracy: 0.4313 - val_loss: 1.7514 - val_macro_f1: 0.3414\n",
      "Epoch 9/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 289ms/step - accuracy: 0.9985 - loss: 0.0174 - val_accuracy: 0.4758 - val_loss: 1.6448 - val_macro_f1: 0.4339\n",
      "Epoch 10/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 291ms/step - accuracy: 0.9995 - loss: 0.0107 - val_accuracy: 0.5164 - val_loss: 1.5587 - val_macro_f1: 0.4511\n",
      "Epoch 11/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.5242 - val_loss: 1.5673 - val_macro_f1: 0.4781\n",
      "Epoch 12/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 300ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.5474 - val_loss: 1.5869 - val_macro_f1: 0.5026\n",
      "Epoch 13/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 293ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.5397 - val_loss: 1.6186 - val_macro_f1: 0.4956\n",
      "Epoch 14/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 276ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.5455 - val_loss: 1.6578 - val_macro_f1: 0.5063\n",
      "Epoch 15/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 280ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.5455 - val_loss: 1.6728 - val_macro_f1: 0.5069\n",
      "Epoch 16/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 278ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.5513 - val_loss: 1.6626 - val_macro_f1: 0.5223\n",
      "Epoch 17/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Non Improvement detected at EP : 16, f1 : 0.5133370790377404\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 298ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.5493 - val_loss: 1.6496 - val_macro_f1: 0.5133\n",
      "Epoch 18/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Non Improvement detected at EP : 17, f1 : 0.5099048276440158\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 284ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.5513 - val_loss: 1.6617 - val_macro_f1: 0.5099\n",
      "Epoch 19/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 285ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.5590 - val_loss: 1.6960 - val_macro_f1: 0.5212\n",
      "Epoch 20/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 272ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.5571 - val_loss: 1.7236 - val_macro_f1: 0.5273\n",
      "Epoch 21/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Non Improvement detected at EP : 20, f1 : 0.5064371851640207\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 279ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.5435 - val_loss: 1.7425 - val_macro_f1: 0.5064\n",
      "Epoch 22/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 276ms/step - accuracy: 1.0000 - loss: 9.4251e-04 - val_accuracy: 0.5532 - val_loss: 1.8202 - val_macro_f1: 0.5221\n",
      "Epoch 23/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 8.6856e-04\n",
      "Non Improvement detected at EP : 22, f1 : 0.5102987856113766\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 265ms/step - accuracy: 1.0000 - loss: 8.4957e-04 - val_accuracy: 0.5377 - val_loss: 1.7755 - val_macro_f1: 0.5103\n",
      "Epoch 24/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 1.0000 - loss: 7.7940e-04\n",
      "Non Improvement detected at EP : 23, f1 : 0.5075088709790121\n",
      "\n",
      "Stopping at EP : 23, f1 : 0.5075088709790121\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 262ms/step - accuracy: 1.0000 - loss: 7.5828e-04 - val_accuracy: 0.5338 - val_loss: 1.8333 - val_macro_f1: 0.5075\n",
      "[hl200x2] Fold 2: loss=1.8333, acc=0.5338, prec_macro=0.5523, f1_macro=0.5273\n",
      "\n",
      "[hl200x2] Fold 3/5\n",
      "Epoch 1/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 258ms/step - accuracy: 0.2679 - loss: 2.1420 - val_accuracy: 0.1973 - val_loss: 2.6892 - val_macro_f1: 0.1130\n",
      "Epoch 2/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 295ms/step - accuracy: 0.5343 - loss: 1.3014 - val_accuracy: 0.1489 - val_loss: 2.3558 - val_macro_f1: 0.1225\n",
      "Epoch 3/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 353ms/step - accuracy: 0.7742 - loss: 0.6908 - val_accuracy: 0.1161 - val_loss: 2.9478 - val_macro_f1: 0.0954\n",
      "Epoch 4/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 318ms/step - accuracy: 0.9241 - loss: 0.3443 - val_accuracy: 0.3095 - val_loss: 2.4982 - val_macro_f1: 0.2173\n",
      "Epoch 5/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 359ms/step - accuracy: 0.9599 - loss: 0.1961 - val_accuracy: 0.1451 - val_loss: 3.2932 - val_macro_f1: 0.0985\n",
      "Epoch 6/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 318ms/step - accuracy: 0.9758 - loss: 0.1291 - val_accuracy: 0.3075 - val_loss: 3.3240 - val_macro_f1: 0.1630\n",
      "Epoch 7/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 302ms/step - accuracy: 0.9898 - loss: 0.0810 - val_accuracy: 0.3482 - val_loss: 2.5513 - val_macro_f1: 0.3222\n",
      "Epoch 8/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 295ms/step - accuracy: 0.9932 - loss: 0.0519 - val_accuracy: 0.4429 - val_loss: 1.8721 - val_macro_f1: 0.4559\n",
      "Epoch 9/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 268ms/step - accuracy: 0.9981 - loss: 0.0291 - val_accuracy: 0.4855 - val_loss: 1.8218 - val_macro_f1: 0.4496\n",
      "Epoch 10/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 266ms/step - accuracy: 0.9985 - loss: 0.0127 - val_accuracy: 0.5048 - val_loss: 1.6235 - val_macro_f1: 0.4843\n",
      "Epoch 11/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 273ms/step - accuracy: 0.9995 - loss: 0.0138 - val_accuracy: 0.5106 - val_loss: 1.5954 - val_macro_f1: 0.4885\n",
      "Epoch 12/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 271ms/step - accuracy: 0.9995 - loss: 0.0092 - val_accuracy: 0.5126 - val_loss: 1.5973 - val_macro_f1: 0.4849\n",
      "Epoch 13/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 284ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.5048 - val_loss: 1.6122 - val_macro_f1: 0.4753\n",
      "Epoch 14/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 274ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.5106 - val_loss: 1.6378 - val_macro_f1: 0.4879\n",
      "Epoch 15/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 284ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.5145 - val_loss: 1.6644 - val_macro_f1: 0.4977\n",
      "Epoch 16/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 282ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.5145 - val_loss: 1.6851 - val_macro_f1: 0.4995\n",
      "Epoch 17/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 345ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.5184 - val_loss: 1.7031 - val_macro_f1: 0.5020\n",
      "Epoch 18/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Non Improvement detected at EP : 17, f1 : 0.5005599055841886\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.5184 - val_loss: 1.7193 - val_macro_f1: 0.5006\n",
      "Epoch 19/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.5203 - val_loss: 1.7346 - val_macro_f1: 0.5027\n",
      "Epoch 20/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 298ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.5203 - val_loss: 1.7487 - val_macro_f1: 0.5027\n",
      "Epoch 21/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Non Improvement detected at EP : 20, f1 : 0.4979269143113425\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 297ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.5184 - val_loss: 1.7624 - val_macro_f1: 0.4979\n",
      "Epoch 22/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 296ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.5203 - val_loss: 1.7757 - val_macro_f1: 0.5000\n",
      "Epoch 23/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.5203 - val_loss: 1.7874 - val_macro_f1: 0.5005\n",
      "Epoch 24/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Non Improvement detected at EP : 23, f1 : 0.4930090662636509\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.5145 - val_loss: 1.8006 - val_macro_f1: 0.4930\n",
      "Epoch 25/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 299ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5184 - val_loss: 1.8150 - val_macro_f1: 0.5007\n",
      "Epoch 26/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Non Improvement detected at EP : 25, f1 : 0.49466074663747467\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 9.9671e-04 - val_accuracy: 0.5164 - val_loss: 1.8179 - val_macro_f1: 0.4947\n",
      "Epoch 27/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 1.0000 - loss: 9.5524e-04\n",
      "Non Improvement detected at EP : 26, f1 : 0.49173054296224034\n",
      "\n",
      "Stopping at EP : 26, f1 : 0.49173054296224034\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 295ms/step - accuracy: 1.0000 - loss: 8.7328e-04 - val_accuracy: 0.5126 - val_loss: 1.8413 - val_macro_f1: 0.4917\n",
      "[hl200x2] Fold 3: loss=1.8413, acc=0.5126, prec_macro=0.5018, f1_macro=0.5027\n",
      "\n",
      "[hl200x2] Fold 4/5\n",
      "Epoch 1/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 281ms/step - accuracy: 0.2548 - loss: 2.0491 - val_accuracy: 0.1122 - val_loss: 3.8242 - val_macro_f1: 0.0641\n",
      "Epoch 2/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 291ms/step - accuracy: 0.6011 - loss: 1.1147 - val_accuracy: 0.3133 - val_loss: 2.1585 - val_macro_f1: 0.1565\n",
      "Epoch 3/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 300ms/step - accuracy: 0.8356 - loss: 0.4904 - val_accuracy: 0.2747 - val_loss: 2.4749 - val_macro_f1: 0.0706\n",
      "Epoch 4/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 285ms/step - accuracy: 0.9541 - loss: 0.1833 - val_accuracy: 0.3153 - val_loss: 2.3458 - val_macro_f1: 0.1442\n",
      "Epoch 5/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 277ms/step - accuracy: 0.9884 - loss: 0.0995 - val_accuracy: 0.3133 - val_loss: 2.6047 - val_macro_f1: 0.1620\n",
      "Epoch 6/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 270ms/step - accuracy: 0.9947 - loss: 0.0531 - val_accuracy: 0.3385 - val_loss: 2.1325 - val_macro_f1: 0.2897\n",
      "Epoch 7/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 263ms/step - accuracy: 0.9971 - loss: 0.0326 - val_accuracy: 0.4352 - val_loss: 1.8854 - val_macro_f1: 0.3774\n",
      "Epoch 8/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 263ms/step - accuracy: 0.9995 - loss: 0.0149 - val_accuracy: 0.4720 - val_loss: 1.8165 - val_macro_f1: 0.3330\n",
      "Epoch 9/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 264ms/step - accuracy: 0.9995 - loss: 0.0087 - val_accuracy: 0.5513 - val_loss: 1.4874 - val_macro_f1: 0.4947\n",
      "Epoch 10/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 266ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.5609 - val_loss: 1.4348 - val_macro_f1: 0.5112\n",
      "Epoch 11/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 272ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.5648 - val_loss: 1.4339 - val_macro_f1: 0.5159\n",
      "Epoch 12/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 271ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.5590 - val_loss: 1.4434 - val_macro_f1: 0.5135\n",
      "Epoch 13/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 278ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.5667 - val_loss: 1.4547 - val_macro_f1: 0.5244\n",
      "Epoch 14/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.5725 - val_loss: 1.4656 - val_macro_f1: 0.5289\n",
      "Epoch 15/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.5764 - val_loss: 1.4750 - val_macro_f1: 0.5331\n",
      "Epoch 16/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 294ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.5764 - val_loss: 1.4825 - val_macro_f1: 0.5315\n",
      "Epoch 17/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 289ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.5803 - val_loss: 1.4915 - val_macro_f1: 0.5411\n",
      "Epoch 18/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 272ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.5822 - val_loss: 1.5000 - val_macro_f1: 0.5455\n",
      "Epoch 19/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 271ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.5822 - val_loss: 1.5070 - val_macro_f1: 0.5455\n",
      "Epoch 20/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Non Improvement detected at EP : 19, f1 : 0.5453436327506974\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 264ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.5822 - val_loss: 1.5143 - val_macro_f1: 0.5453\n",
      "Epoch 21/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 268ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.5861 - val_loss: 1.5209 - val_macro_f1: 0.5495\n",
      "Epoch 22/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Non Improvement detected at EP : 21, f1 : 0.5461633237798055\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 267ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5822 - val_loss: 1.5276 - val_macro_f1: 0.5462\n",
      "Epoch 23/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 0.0010\n",
      "Non Improvement detected at EP : 22, f1 : 0.5461553406705565\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 266ms/step - accuracy: 1.0000 - loss: 9.9699e-04 - val_accuracy: 0.5822 - val_loss: 1.5339 - val_macro_f1: 0.5462\n",
      "Epoch 24/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 9.3939e-04\n",
      "Non Improvement detected at EP : 23, f1 : 0.5451664946071665\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 264ms/step - accuracy: 1.0000 - loss: 9.2094e-04 - val_accuracy: 0.5822 - val_loss: 1.5399 - val_macro_f1: 0.5452\n",
      "Epoch 25/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 8.6976e-04\n",
      "Non Improvement detected at EP : 24, f1 : 0.5418465489427947\n",
      "\n",
      "Stopping at EP : 24, f1 : 0.5418465489427947\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 272ms/step - accuracy: 1.0000 - loss: 8.5303e-04 - val_accuracy: 0.5783 - val_loss: 1.5462 - val_macro_f1: 0.5418\n",
      "[hl200x2] Fold 4: loss=1.5462, acc=0.5783, prec_macro=0.5795, f1_macro=0.5495\n",
      "\n",
      "[hl200x2] Fold 5/5\n",
      "Epoch 1/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 277ms/step - accuracy: 0.2756 - loss: 2.0049 - val_accuracy: 0.1954 - val_loss: 4.7909 - val_macro_f1: 0.0911\n",
      "Epoch 2/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 271ms/step - accuracy: 0.6407 - loss: 0.9818 - val_accuracy: 0.1528 - val_loss: 2.9036 - val_macro_f1: 0.1115\n",
      "Epoch 3/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 276ms/step - accuracy: 0.8975 - loss: 0.3679 - val_accuracy: 0.1238 - val_loss: 3.4439 - val_macro_f1: 0.0889\n",
      "Epoch 4/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 292ms/step - accuracy: 0.9778 - loss: 0.1282 - val_accuracy: 0.2418 - val_loss: 2.6089 - val_macro_f1: 0.1333\n",
      "Epoch 5/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 299ms/step - accuracy: 0.9903 - loss: 0.0730 - val_accuracy: 0.2650 - val_loss: 2.3822 - val_macro_f1: 0.1873\n",
      "Epoch 6/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 293ms/step - accuracy: 0.9976 - loss: 0.0427 - val_accuracy: 0.2747 - val_loss: 2.2511 - val_macro_f1: 0.2269\n",
      "Epoch 7/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 281ms/step - accuracy: 0.9995 - loss: 0.0183 - val_accuracy: 0.4043 - val_loss: 2.0510 - val_macro_f1: 0.3169\n",
      "Epoch 8/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 285ms/step - accuracy: 0.9990 - loss: 0.0120 - val_accuracy: 0.4855 - val_loss: 1.7143 - val_macro_f1: 0.4429\n",
      "Epoch 9/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 294ms/step - accuracy: 0.9995 - loss: 0.0134 - val_accuracy: 0.4797 - val_loss: 1.6974 - val_macro_f1: 0.4281\n",
      "Epoch 10/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.5087 - val_loss: 1.6386 - val_macro_f1: 0.4600\n",
      "Epoch 11/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 289ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.5280 - val_loss: 1.6065 - val_macro_f1: 0.4846\n",
      "Epoch 12/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 287ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.5300 - val_loss: 1.6198 - val_macro_f1: 0.4863\n",
      "Epoch 13/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 286ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.5377 - val_loss: 1.6308 - val_macro_f1: 0.4983\n",
      "Epoch 14/50\n",
      "\u001b[1m21/65\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 257ms/step - accuracy: 1.0000 - loss: 0.0029"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "\n",
    "# ----- 설정 값들 -----\n",
    "N_SPLITS   = 5      # k-fold 개수\n",
    "EPOCHS     = 50     # 최대 epoch\n",
    "BATCH_SIZE = 32\n",
    "#CONFIG_INDEX = 0\n",
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=N_SPLITS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "test_configs = configs[4:]\n",
    "\n",
    "for cfg in test_configs:\n",
    "    name = cfg[\"name\"]\n",
    "    print(f\"\\n===== K-Fold CV for config: {name} =====\")\n",
    "\n",
    "    fold_accuracies = []\n",
    "    fold_precisions = []\n",
    "    fold_f1s        = []\n",
    "    fold_last_f1s   = []\n",
    "\n",
    "    # k-fold 루프\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_rest, y_rest), start=1):\n",
    "        print(f\"\\n[{name}] Fold {fold_idx}/{N_SPLITS}\")\n",
    "\n",
    "        X_tr, X_val = X_rest[train_idx], X_rest[val_idx]\n",
    "        y_tr, y_val = y_rest[train_idx], y_rest[val_idx]\n",
    "\n",
    "        # 모델 생성(컴파일도 여기서 진행!)\n",
    "        model = build_model(**cfg)\n",
    "        #model.summary() #debug\n",
    "\n",
    "        # f1 + early stopping\n",
    "        f1_cb = F1ScoreCallback(\n",
    "            X_val, y_val,\n",
    "            start_from_epoch=15,\n",
    "            patient=5\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            X_tr, y_tr,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks=[f1_cb],\n",
    "            class_weight=class_weight_dict, #이렇게 하면 class weight를 줄 수 있음. 근데 그냥 이렇게 하고 끝낼 예정...\n",
    "            verbose=1,   # 필요하면 1로 바꿔도 됨\n",
    "        )\n",
    "\n",
    "        # ---- 이 fold에서 metrics 계산 ----\n",
    "        # 1) loss / accuracy (evaluate)\n",
    "        loss, acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "        # 2) 예측값 가져와서 precision / f1 (macro) 계산\n",
    "        y_prob = model.predict(X_val, verbose=0)\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "        y_true = y_val\n",
    "\n",
    "        precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        f1        = f1_cb.best_f1\n",
    "        last_f1   = f1_cb.f1_scores[-1]\n",
    "\n",
    "        fold_accuracies.append(acc)\n",
    "        fold_precisions.append(precision)\n",
    "        fold_f1s.append(f1)\n",
    "        fold_last_f1s.append(last_f1)\n",
    "\n",
    "        print(f\"[{name}] Fold {fold_idx}: \"\n",
    "              f\"loss={loss:.4f}, acc={acc:.4f}, \"\n",
    "              f\"prec_macro={precision:.4f}, f1_macro={f1:.4f}\")\n",
    "\n",
    "        #now this actually helps\n",
    "        del model\n",
    "        model = None\n",
    "        gc.collect()\n",
    "\n",
    "    # ----- config별 평균/표준편차 정리 -----\n",
    "    cfg_row = {\n",
    "        \"name\": name,\n",
    "        \"acc_mean\":  float(np.mean(fold_accuracies)),\n",
    "        \"acc_std\":   float(np.std(fold_accuracies)),\n",
    "        \"prec_macro_mean\": float(np.mean(fold_precisions)),\n",
    "        \"prec_macro_std\":  float(np.std(fold_precisions)),\n",
    "        \"best_f1_macro_mean\":   float(np.mean(fold_f1s)),\n",
    "        \"best_f1_macro_std\":    float(np.std(fold_f1s)),\n",
    "        \"last_f1_macro_mean\":   float(np.mean(fold_last_f1s)),\n",
    "        \"last_f1_macro_std\":    float(np.std(fold_last_f1s)),\n",
    "    }\n",
    "\n",
    "    print(f\"\\n>>> [CV Summary] {name}: \"\n",
    "          f\"f1_macro={cfg_row['best_f1_macro_mean']:.4f} ± {cfg_row['best_f1_macro_std']:.4f}, \"\n",
    "          f\"last_f1_macro={cfg_row['last_f1_macro_mean']:.4f} ± {cfg_row['last_f1_macro_std']:.4f}, \"\n",
    "          f\"acc={cfg_row['acc_mean']:.4f} ± {cfg_row['acc_std']:.4f}, \")\n",
    "\n",
    "    cv_results.append(cfg_row)\n",
    "    print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "XorvY4lmYji3",
   "metadata": {
    "id": "XorvY4lmYji3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-Fold 결과 best_f1_macro_mean DESC\n",
      "              name  acc_mean  acc_std  prec_macro_mean  prec_macro_std  best_f1_macro_mean  best_f1_macro_std  last_f1_macro_mean  last_f1_macro_std\n",
      "           hl300x2  0.539265 0.014751         0.540555        0.015302            0.522504           0.013446            0.513433           0.015328\n",
      "           hl300x3  0.545068 0.010901         0.554231        0.019216            0.511060           0.014264            0.498991           0.014582\n",
      "        cl16_32_64  0.535397 0.010832         0.536960        0.016697            0.506638           0.011692            0.502457           0.010623\n",
      "hl300x2_100x2_50x2  0.510251 0.033667         0.566498        0.045067            0.490764           0.017120            0.464768           0.031682\n",
      "           hl100x4  0.517602 0.006309         0.546708        0.021414            0.488260           0.012076            0.478842           0.018194\n"
     ]
    }
   ],
   "source": [
    "cv_df = pd.DataFrame(cv_results).sort_values(\"best_f1_macro_mean\", ascending=False)\n",
    "print(\"\\nK-Fold 결과 best_f1_macro_mean DESC\")\n",
    "print(cv_df.to_string(index=False))\n",
    "\n",
    "kfold_result_csv_path = DATA_DIR / \"kfold_result_class.csv\"\n",
    "\n",
    "cv_df.to_csv(kfold_result_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32653095-f0e7-4faa-ac0d-8bb49a15b9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02ebafc09f1a4e7ba20e2a1cf9fccfe9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81589a93cdd848358ce75973668acdbc",
      "placeholder": "​",
      "style": "IPY_MODEL_837cd80e9aec4987a0bfe36254a53c4c",
      "value": "Processing Images: 100%"
     }
    },
    "0bf88e29d24f4c1c8da7ca5f681233dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "153e3daeac704ae8bd3a845e761f5c69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_02ebafc09f1a4e7ba20e2a1cf9fccfe9",
       "IPY_MODEL_5087e63df54a4a7aa2c8fdbee60dda43",
       "IPY_MODEL_9b6363585a834d68b424bd09693be95e"
      ],
      "layout": "IPY_MODEL_5a37bae3144f4a5ebc361db1d02ecc15"
     }
    },
    "2c08b7b452be4dff98eb95d8a2aaeb91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5087e63df54a4a7aa2c8fdbee60dda43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c08b7b452be4dff98eb95d8a2aaeb91",
      "max": 3042,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cbcf43f91a824e80aa0745e3cc57e6b3",
      "value": 3042
     }
    },
    "5a37bae3144f4a5ebc361db1d02ecc15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81589a93cdd848358ce75973668acdbc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "837cd80e9aec4987a0bfe36254a53c4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93a9cd26f71f4ff8ac955fcfc8208bef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b6363585a834d68b424bd09693be95e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bf88e29d24f4c1c8da7ca5f681233dc",
      "placeholder": "​",
      "style": "IPY_MODEL_93a9cd26f71f4ff8ac955fcfc8208bef",
      "value": " 3042/3042 [00:29&lt;00:00, 118.56img/s]"
     }
    },
    "cbcf43f91a824e80aa0745e3cc57e6b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
